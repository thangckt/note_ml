

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>The Three Most Common Errors in PyTorch</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/sphinx_highlight.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebook/pytorch_deep_learning/extras/pytorch_most_common_errors';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Setup to code PyTorch" href="pytorch_setup.html" />
    <link rel="prev" title="PyTorch Cheatsheet" href="pytorch_cheatsheet.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../README.html">
  
  
  
  
  
  
    <p class="title logo__title"></p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic of ML &amp; DL</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../0_basic_MLDL/1_0_ml_overview.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../0_basic_MLDL/1_1_ml_supervised_unsuppersives.html">Supervised vs. Unsuppervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../0_basic_MLDL/1_2_regression.html">Regression &amp; Model Assessment</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../0_basic_MLDL/2_0_dl_overview.html">Deep Learning Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../0_basic_MLDL/2_1_dl_neural_network.html">What is a neural network?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../0_basic_MLDL/2_2_layers.html">Standard Layers</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../0_basic_MLDL/3_1_workflow.html">Workflow in ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../0_basic_MLDL/3_2_Model_template.html">Core Ml templates</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PyTorch for Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_pytorch_fundamentals.html">00. PyTorch Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01_pytorch_workflow.html">01. PyTorch Workflow Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02_pytorch_classification.html">02. PyTorch Neural Network Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../03_pytorch_computer_vision.html">03. PyTorch Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04_pytorch_custom_datasets.html">04. PyTorch Custom Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05_pytorch_going_modular.html">05. PyTorch Going Modular</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06_pytorch_transfer_learning.html">06. PyTorch Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07_pytorch_experiment_tracking.html">07. PyTorch Experiment Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08_pytorch_paper_replicating.html">08. PyTorch Paper Replicating</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09_pytorch_model_deployment.html">09. PyTorch Model Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_extra_resources.html">PyTorch Extra Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_cheatsheet.html">PyTorch Cheatsheet</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The Three Most Common Errors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="pytorch_setup.html">Setup to code PyTorch</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Zero to Mastery Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../zero_to_mastery_ml/README.html">Zero to Mastery Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Practices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../1_Practices/1_PT_Linear_Regression.html">Linear Regression</a></li>





<li class="toctree-l1"><a class="reference internal" href="../../1_Practices/2_PT_Logistic_Regression.html">Logistic Regression</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/thangckt/note_ml/edit/main/notebook/pytorch_deep_learning/extras/pytorch_most_common_errors.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button"
   title="Suggest edit"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The Three Most Common Errors in PyTorch</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-errors-in-pytorch">1. Shape errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-multiplication-shape-errors">1.1 Matrix multiplication shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-neural-network-shape-errors">1.2 PyTorch neural network shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#downloading-a-dataset">1.3 Downloading a dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-series-of-neural-networks-with-different-shape-errors">1.4 Building a series of neural networks with different shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incorrect-input-layer-shapes">1.5 Incorrect input layer shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incorrect-hidden-layer-input-and-output-shapes">1.6 Incorrect hidden layer input and output shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-lazy-layers-automatically-inferring-the-input-shape">1.7 PyTorch lazy layers (automatically inferring the input shape)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#device-errors-in-pytorch">2. Device errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-target-device">2.1 Setting the target device</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-data-for-modelling">2.2 Preparing data for modelling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-model-on-the-cpu">2.3 Training a model on the CPU</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attempting-to-train-a-model-on-the-gpu-with-errors">2.4 Attempting to train a model on the GPU (with errors)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-model-on-the-gpu-without-errors">2.5 Training a model on the GPU (without errors)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-errors-when-making-predictions">2.6 Device errors when making predictions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datatype-errors-in-pytorch">3. Datatype errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-datatype-of-the-data-the-model-was-trained-on">3.1 Checking the datatype of the data the model was trained on</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#changing-the-datatype-of-a-tensor">3.2 Changing the datatype of a tensor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#making-predictions-on-a-test-image-and-making-sure-its-in-the-right-format">3.3 Making predictions on a test image and making sure it’s in the right format</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a href="https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/pytorch_most_common_errors.ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section class="tex2jax_ignore mathjax_ignore" id="the-three-most-common-errors-in-pytorch">
<h1>The Three Most Common Errors in PyTorch<a class="headerlink" href="#the-three-most-common-errors-in-pytorch" title="Permalink to this heading">#</a></h1>
<p>PyTorch is one of the largest machine learning libraries available.</p>
<p>So it’s likely you’ll run into various errors when using it.</p>
<p>Because of the various maintenance and checks performed by the creators, it’s rare the error will be because of the library itself.</p>
<p>This means the majority of the errors you run into will be user errors.</p>
<p>More specifically, you wrote the wrong code.</p>
<p>Don’t be offended, this happens to every programmer.</p>
<p>Of the user errors you run into, chances are they’ll be one of the following:</p>
<ol class="arabic simple">
<li><p><strong>Shape errors</strong> - You’re trying to perform an operation on matrices/tensors with shapes that don’t line up. For example, your data’s shape is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">28,</span> <span class="pre">28]</span></code> but your first layer takes an input of <code class="docutils literal notranslate"><span class="pre">[10]</span></code>.</p></li>
<li><p><strong>Device errors</strong> - Your model is on a different device to your data. For example your model is on the GPU (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code>) and your data is on the CPU (e.g. <code class="docutils literal notranslate"><span class="pre">&quot;cpu&quot;</span></code>).</p></li>
<li><p><strong>Datatype errors</strong> - Your data is one datatype (e.g. <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>), however the operation you’re trying to perform requires another datatype (e.g. <code class="docutils literal notranslate"><span class="pre">torch.int64</span></code>).</p></li>
</ol>
<a class="reference internal image-reference" href="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/misc-three-main-errors-in-pytorch.png"><img alt="the three most common errors in PyTorch" src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/misc-three-main-errors-in-pytorch.png" style="width: 750px;" /></a>
<p>Notice the recurring theme here.</p>
<p>There’s some kind of mismatch between your shape(s), device(s) and/or datatype(s).</p>
<p>This notebook/blog post goes through examples of each of the above errors and how to fix them.</p>
<p>It won’t prevent you from making them in the future but it will make you aware enough to perhaps reduce them and even more important, know how to solve them.</p>
<blockquote>
<div><p><strong>Note:</strong> All of the following examples have been adapted from <a class="reference external" href="https://learnpytorch.io">learnpytorch.io</a> which is the book version of the <a class="reference external" href="https://dbourke.link/ZTMPyTorch">Zero to Mastery: PyTorch for Deep Learning</a> video course.</p>
</div></blockquote>
<section id="shape-errors-in-pytorch">
<h2>1. Shape errors in PyTorch<a class="headerlink" href="#shape-errors-in-pytorch" title="Permalink to this heading">#</a></h2>
<section id="matrix-multiplication-shape-errors">
<h3>1.1 Matrix multiplication shape errors<a class="headerlink" href="#matrix-multiplication-shape-errors" title="Permalink to this heading">#</a></h3>
<p>PyTorch is one of the best frameworks to build neural network models with.</p>
<p>And one of the fundamental operations of a neural network is matrix multiplication.</p>
<p>However, matrix multiplication comes with very specific rules.</p>
<p>If these rules aren’t adhered to, you’ll get an infamous shape error.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">3</span><span class="n">x4</span> <span class="ow">and</span> <span class="mi">3</span><span class="n">x4</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s start with a brief example.</p>
<blockquote>
<div><p><strong>Note:</strong> Although it’s called “matrix multiplication” almost every form of data in PyTorch comes in the form of a tensor. Where a tensor is an n-dimensional array (n can be any number). So while I use the terminology “matrix multiplication”, this extends to “tensor multiplication” as well. See <a class="reference external" href="https://www.learnpytorch.io/00_pytorch_fundamentals/#introduction-to-tensors">00. PyTorch Fundamentals: Introduction to Tensors</a> for more on the difference between matrices and tensors.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>PyTorch version: 1.12.1+cu113
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create two tensors</span>
<span class="n">tensor_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="c1"># Check the shapes</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tensor_2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([3, 4])
torch.Size([3, 4])
</pre></div>
</div>
</div>
</div>
<p>Notice both tensors have the same shape.</p>
<p>Let’s try to perform a matrix multiplication on them.</p>
<blockquote>
<div><p><strong>Note:</strong> The matrix multiplication operation is different to a standard multiplication operation.</p>
<p>With our current tensors, the standard multiplication operation (<code class="docutils literal notranslate"><span class="pre">*</span></code> or <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.mul.html"><code class="docutils literal notranslate"><span class="pre">torch.mul()</span></code></a>) will work where as the matrix multiplication operation (<code class="docutils literal notranslate"><span class="pre">&#64;</span></code> or <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.matmul.html"><code class="docutils literal notranslate"><span class="pre">torch.matmul()</span></code></a>) will error.</p>
<p>See <a class="reference external" href="https://www.learnpytorch.io/00_pytorch_fundamentals/#matrix-multiplication-is-all-you-need">00. PyTorch Fundamentals: Matrix Multiplication</a> for a breakdown of what happens in matrix multiplication.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Standard multiplication, the following lines perform the same operation (will work)</span>
<span class="n">tensor_3</span> <span class="o">=</span> <span class="n">tensor_1</span> <span class="o">*</span> <span class="n">tensor_2</span> <span class="c1"># can do standard multiplication with &quot;*&quot;</span>
<span class="n">tensor_4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">tensor_1</span><span class="p">,</span> <span class="n">tensor_2</span><span class="p">)</span> <span class="c1"># can also do standard multiplicaton with &quot;torch.mul()&quot; </span>

<span class="c1"># Check for equality </span>
<span class="n">tensor_3</span> <span class="o">==</span> <span class="n">tensor_4</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[True, True, True, True],
        [True, True, True, True],
        [True, True, True, True]])
</pre></div>
</div>
</div>
</div>
<p>Wonderful! Looks like standard multiplication works with our current tensor shapes.</p>
<p>Let’s try matrix multiplication.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Try matrix multiplication (won&#39;t work)</span>
<span class="n">tensor_5</span> <span class="o">=</span> <span class="n">tensor_1</span> <span class="o">@</span> <span class="n">tensor_2</span> <span class="c1"># could also do &quot;torch.matmul(tensor_1, tensor_2)&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [4],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Try matrix multiplication (won&#39;t work)</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">tensor_5</span> <span class="o">=</span> <span class="n">tensor_1</span> <span class="o">@</span> <span class="n">tensor_2</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)
</pre></div>
</div>
</div>
</div>
<p>Oh no!</p>
<p>We get an error similar to the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span>                              <span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">11</span><span class="o">-</span><span class="mi">2</span><span class="n">ca2c90dbb42</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
      <span class="mi">1</span> <span class="c1"># Try matrix multiplication (won&#39;t work)</span>
<span class="o">----&gt;</span> <span class="mi">2</span> <span class="n">tensor_5</span> <span class="o">=</span> <span class="n">tensor_1</span> <span class="o">@</span> <span class="n">tensor_2</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">3</span><span class="n">x4</span> <span class="ow">and</span> <span class="mi">3</span><span class="n">x4</span><span class="p">)</span>
</pre></div>
</div>
<p>This is a <strong>shape error</strong>, our two tensors (matrices) can’t be <em>matrix</em> multiplied because their shapes are incompatible.</p>
<p>Why?</p>
<p>This is because matrix multiplication has specific rules:</p>
<ol class="arabic simple">
<li><p>The <strong>inner dimensions</strong> must match:</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4)</span> <span class="pre">&#64;</span> <span class="pre">(3,</span> <span class="pre">4)</span></code> won’t work</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">3)</span> <span class="pre">&#64;</span> <span class="pre">(3,</span> <span class="pre">4)</span></code> will work</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4)</span> <span class="pre">&#64;</span> <span class="pre">(4,</span> <span class="pre">3)</span></code> will work</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>The resulting matrix has the shape of the <strong>outer dimensions</strong>:</p></li>
</ol>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">3)</span> <span class="pre">&#64;</span> <span class="pre">(3,</span> <span class="pre">4)</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">4)</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4)</span> <span class="pre">&#64;</span> <span class="pre">(4,</span> <span class="pre">3)</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3)</span></code></p></li>
</ul>
<p>So how do we fix it?</p>
<p>This where either a <em>transpose</em> or a <em>reshape</em> comes in.</p>
<p>And in the case of neural networks, it’s more generally a transpose operation.</p>
<ul class="simple">
<li><p><strong>Transpose</strong> - The transpose (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.transpose.html"><code class="docutils literal notranslate"><span class="pre">torch.transpose()</span></code></a>) operation swaps the dimensions of a given tensor.</p>
<ul>
<li><p><strong>Note:</strong> You can also use the shortcut of <code class="docutils literal notranslate"><span class="pre">tensor.T</span></code> to perform a transpose.</p></li>
</ul>
</li>
<li><p><strong>Reshape</strong> - The reshape (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.reshape.html"><code class="docutils literal notranslate"><span class="pre">torch.reshape()</span></code></a>) operation returns a tensor with the same number of original elements but in a different specified shape.</p></li>
</ul>
<p>Let’s see this in action.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform a transpose on tensor_1 and then perform matrix multiplication </span>
<span class="n">tensor_6</span> <span class="o">=</span> <span class="n">tensor_1</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">tensor_2</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of input tensors: </span><span class="si">{</span><span class="n">tensor_1</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">tensor_2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of output tensor: </span><span class="si">{</span><span class="n">tensor_6</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of input tensors: torch.Size([4, 3]) and torch.Size([3, 4])
Shape of output tensor: torch.Size([4, 4])
</pre></div>
</div>
</div>
</div>
<p>No errors!</p>
<p>See how the input shape of <code class="docutils literal notranslate"><span class="pre">tensor_1</span></code> changed from <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">4)</span></code> to <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">3)</span></code> thanks to the transpose (<code class="docutils literal notranslate"><span class="pre">tensor_1.T</span></code>).</p>
<p>And because of this, rule 1 of matrix multiplication, <strong>the inner dimensions must match</strong> was satisfied.</p>
<p>Finally, the output shape satisfied rule 2 of matrix multiplication, <strong>the resulting matrix has the shape of the outer dimensions</strong>.</p>
<p>In our case, <code class="docutils literal notranslate"><span class="pre">tensor_6</span></code> has a shape of <code class="docutils literal notranslate"><span class="pre">(4,</span> <span class="pre">4)</span></code>.</p>
<p>Let’s do the same operation except now we’ll transpose <code class="docutils literal notranslate"><span class="pre">tensor_2</span></code> instead of <code class="docutils literal notranslate"><span class="pre">tensor_1</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Perform a transpose on tensor_2 and then perform matrix multiplication</span>
<span class="n">tensor_7</span> <span class="o">=</span> <span class="n">tensor_1</span> <span class="o">@</span> <span class="n">tensor_2</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of input tensors: </span><span class="si">{</span><span class="n">tensor_1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">tensor_2</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of output tensor: </span><span class="si">{</span><span class="n">tensor_7</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of input tensors: torch.Size([3, 4]) and torch.Size([4, 3])
Shape of output tensor: torch.Size([3, 3])
</pre></div>
</div>
</div>
</div>
<p>Woohoo!</p>
<p>No errors again!</p>
<p>See how rule 1 and rule 2 of matrix multiplication were satisfied again.</p>
<p>Except this time because we transposed <code class="docutils literal notranslate"><span class="pre">tensor_2</span></code>, the resulting output tensor shape is <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">3)</span></code>.</p>
<p>The good news is most of the time, when you build neural networks with PyTorch, the library takes care of most of the matrix multiplication operations you’ll need to perform for you.</p>
<p>With that being said, let’s build a neural network with PyTorch and see where shape errors might occur.</p>
</section>
<section id="pytorch-neural-network-shape-errors">
<h3>1.2 PyTorch neural network shape errors<a class="headerlink" href="#pytorch-neural-network-shape-errors" title="Permalink to this heading">#</a></h3>
<p>We’ve seen how shape errors can occur when working with matrix multiplication (or matrix multiplying tensors).</p>
<p>Now let’s build a neural network with PyTorch and see where shape errors can occur.</p>
<p>A shape error will occur in neural network in any of the following situations:</p>
<ul class="simple">
<li><p><strong>Incorrect input shape</strong> - your data is in a certain shape but the model’s first layer expects a different shape.</p></li>
<li><p><strong>Incorrect input and output shapes between layers</strong> - one of the layers of your model outputs a certain shape but the following layer expects a different shape as input.</p></li>
<li><p><strong>No batch size dimension in input data when trying to make a prediction</strong> - your model was trained on samples with a batch dimension, so when you try to predict on a single sample <em>without</em> a batch dimension, an error occurs.</p></li>
</ul>
<p>To showcase these shape errors, let’s build a simple neural network (the errors are the same regardless of the size of your network) to try and find patterns in the Fashion MNIST dataset (black and white images of 10 different classes of clothing).</p>
<blockquote>
<div><p><strong>Note:</strong> The following examples focus specifically on shape errors rather than building the <em>best</em> neural network. You can see a fully working example of this problem in <a class="reference external" href="https://www.learnpytorch.io/03_pytorch_computer_vision/">03. PyTorch Computer Vision</a>.</p>
</div></blockquote>
</section>
<section id="downloading-a-dataset">
<h3>1.3 Downloading a dataset<a class="headerlink" href="#downloading-a-dataset" title="Permalink to this heading">#</a></h3>
<p>To begin, we’ll get the Fashion MNIST dataset from <a class="reference external" href="https://pytorch.org/vision/stable/generated/torchvision.datasets.FashionMNIST.html"><code class="docutils literal notranslate"><span class="pre">torchvision.datasets</span></code></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="c1"># Setup training data</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span> <span class="c1"># where to download data to?</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># get training data</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="c1"># download data if it doesn&#39;t exist on disk</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="c1"># images come as PIL format, we want to turn into Torch tensors</span>
    <span class="n">target_transform</span><span class="o">=</span><span class="kc">None</span> <span class="c1"># you can transform labels as well</span>
<span class="p">)</span>

<span class="c1"># Setup testing data</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="c1"># get test data</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "966b1ed47e214e189c79c2d1e1c1f2bb", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a4d501453aba4c43bf5ea3e9a12ffe80", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "5a57edd30fc643c0baba05f3595fbe93", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw

Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "f795a425a8d04dd59215f4414997a416", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw
</pre></div>
</div>
</div>
</div>
<p>Now let’s get some details about the first training sample, the label as well as the class names and number of classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See first training sample</span>
<span class="n">image</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Image shape: </span><span class="si">{</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> -&gt; [batch, height, width]&quot;</span><span class="p">)</span> 
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Label: </span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># label is an int rather than a tensor (it has no shape attribute)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Image shape: torch.Size([1, 28, 28]) -&gt; [batch, height, width]
Label: 9
</pre></div>
</div>
</div>
</div>
<p>Our image has a shape of <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">28,</span> <span class="pre">28]</span></code> or <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">height,</span> <span class="pre">width]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># See class names and number of classes</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">classes</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>
<span class="n">class_names</span><span class="p">,</span> <span class="n">num_classes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([&#39;T-shirt/top&#39;,
  &#39;Trouser&#39;,
  &#39;Pullover&#39;,
  &#39;Dress&#39;,
  &#39;Coat&#39;,
  &#39;Sandal&#39;,
  &#39;Shirt&#39;,
  &#39;Sneaker&#39;,
  &#39;Bag&#39;,
  &#39;Ankle boot&#39;],
 10)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot a sample</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span> <span class="c1"># plot image as grayscale</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">label</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4651c738648c8cdac93b185f8ede7e45f18a16eaf0e69557585cc42921ebf93d.png" src="../../../_images/4651c738648c8cdac93b185f8ede7e45f18a16eaf0e69557585cc42921ebf93d.png" />
</div>
</div>
</section>
<section id="building-a-series-of-neural-networks-with-different-shape-errors">
<h3>1.4 Building a series of neural networks with different shape errors<a class="headerlink" href="#building-a-series-of-neural-networks-with-different-shape-errors" title="Permalink to this heading">#</a></h3>
<p>Our problem is: build a neural network capable of finding patterns in grayscale images of clothing.</p>
<p>This statement could go very deep since “what neural network is the best?” is one of the main research problems in machine learning as a whole.</p>
<p>But let’s start as simple as possible to showcase different error types.</p>
<p>We’ll build several two layer neural networks with PyTorch each to showcase a different error:</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Model number</strong></p></th>
<th class="head"><p><strong>Layers</strong></p></th>
<th class="head"><p><strong>Error showcase</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>2 x <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> with 10 hidden units</p></td>
<td><p>Incorrect input shape</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>Same as model 1 + 1 x <code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code></p></td>
<td><p>Incorrect input shape (still)</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>1 x <code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code>, 1 x <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> with correct input shape and 1 x <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> with 10 hidden units</p></td>
<td><p>None (input shape is correct)</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>Same as model 2 but with different shapes between <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layers</p></td>
<td><p>Incorrect shapes between layers</p></td>
</tr>
<tr class="row-even"><td><p>4</p></td>
<td><p>Same as model 3 but with last layer replaced with <code class="docutils literal notranslate"><span class="pre">nn.LazyLinear()</span></code></p></td>
<td><p>None (shows how <code class="docutils literal notranslate"><span class="pre">nn.LazyX()</span></code> layers can infer correct shape)</p></td>
</tr>
<tr class="row-odd"><td><p>5</p></td>
<td><p>Same as model 4 but with all <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> replaced with <code class="docutils literal notranslate"><span class="pre">nn.LazyLinear()</span></code></p></td>
<td><p>None (shows how <code class="docutils literal notranslate"><span class="pre">nn.LazyX()</span></code> layers can infer correct shape)</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="incorrect-input-layer-shapes">
<h3>1.5 Incorrect input layer shapes<a class="headerlink" href="#incorrect-input-layer-shapes" title="Permalink to this heading">#</a></h3>
<p>We’ll start with a two layer network with <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html"><code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code></a> layers with 10 hidden units in each.</p>
<blockquote>
<div><p><strong>Note:</strong> See <a class="reference external" href="https://www.learnpytorch.io/01_pytorch_workflow/#6-putting-it-all-together">01. PyTorch Workflow section 6: Putting it all together</a> for what happens inside <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code>.</p>
</div></blockquote>
<p>And then we’ll pass our <code class="docutils literal notranslate"><span class="pre">image</span></code> through it and see what happens.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Create a two layer neural network</span>
<span class="n">model_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model (this will error)</span>
<span class="n">model_0</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [11],</span> in <span class="ni">&lt;cell line: 10&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="n">model_0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span> <span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="c1"># Pass the image through the model (this will error)</span>
<span class="ne">---&gt; </span><span class="mi">10</span> <span class="n">model_0</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (28x28 and 10x10)
</pre></div>
</div>
</div>
</div>
<p>Running the above code we get another shape error!</p>
<p>Something similar to:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">linear</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="mi">112</span> 
    <span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="o">--&gt;</span> <span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="mi">115</span> 
    <span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">28</span><span class="n">x28</span> <span class="ow">and</span> <span class="mi">10</span><span class="n">x10</span><span class="p">)</span>
</pre></div>
</div>
<p>The key is in the final line <code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">mat1</span> <span class="pre">and</span> <span class="pre">mat2</span> <span class="pre">shapes</span> <span class="pre">cannot</span> <span class="pre">be</span> <span class="pre">multiplied</span> <span class="pre">(28x28</span> <span class="pre">and</span> <span class="pre">10x10)</span></code>.</p>
<p>This is telling us there’s something wrong with our data shapes.</p>
<p>Because behind the scenes, <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> is attempting to do a matrix multiplication.</p>
<p>How do we fix this?</p>
<p>There are several different options depending on what kind of layer(s) you’re using.</p>
<p>But since we’re using <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layers, let’s focus on that.</p>
<p><code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> likes to accept data as a single-dimension vector .</p>
<p>For example, instead of an input <code class="docutils literal notranslate"><span class="pre">image</span></code> shape of <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">28,</span> <span class="pre">28]</span></code>, it would prefer <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">784]</span></code> (<code class="docutils literal notranslate"><span class="pre">784</span> <span class="pre">=</span> <span class="pre">28*28</span></code>).</p>
<p>In other words, it likes all of the information to be <em>flattened</em> into a single dimension.</p>
<p>We can achieve this flattening using PyTorch’s <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html"><code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code></a>.</p>
<p>Let’s see it happen.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a flatten layer</span>
<span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

<span class="c1"># Pass the image through the flatten layer</span>
<span class="n">flattened_image</span> <span class="o">=</span> <span class="n">flatten</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="c1"># Print out the image shape before and after </span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Before flatten shape: </span><span class="si">{</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> -&gt; [batch, height, width]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After flatten shape: </span><span class="si">{</span><span class="n">flattened_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> -&gt; [batch, height*width]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Before flatten shape: torch.Size([1, 28, 28]) -&gt; [batch, height, width]
After flatten shape: torch.Size([1, 784]) -&gt; [batch, height*width]
</pre></div>
</div>
</div>
</div>
<p>Wonderful, image data flattened!</p>
<p>Now let’s try adding the <code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code> layer to our existing model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replicate model_0 except add a nn.Flatten() layer to begin with </span>
<span class="n">model_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="c1"># &lt;-- NEW: add nn.Flatten() layer</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model</span>
<span class="n">model_1</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [13],</span> in <span class="ni">&lt;cell line: 9&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">model_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span> <span class="c1"># &lt;-- NEW: add nn.Flatten() layer</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="c1"># Pass the image through the model</span>
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="n">model_1</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (1x784 and 10x10)
</pre></div>
</div>
</div>
</div>
<p>Oh no!</p>
<p>Another error…</p>
<p>Something like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">linear</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="mi">112</span> 
    <span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="o">--&gt;</span> <span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="mi">115</span> 
    <span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">1</span><span class="n">x784</span> <span class="ow">and</span> <span class="mi">10</span><span class="n">x10</span><span class="p">)</span>
</pre></div>
</div>
<p>Again, the key information is in the bottom line.</p>
<p><code class="docutils literal notranslate"><span class="pre">RuntimeError:</span> <span class="pre">mat1</span> <span class="pre">and</span> <span class="pre">mat2</span> <span class="pre">shapes</span> <span class="pre">cannot</span> <span class="pre">be</span> <span class="pre">multiplied</span> <span class="pre">(1x784</span> <span class="pre">and</span> <span class="pre">10x10)</span></code></p>
<p>Hmm, we know the <code class="docutils literal notranslate"><span class="pre">(1x784)</span></code> must be coming from our input data (<code class="docutils literal notranslate"><span class="pre">image</span></code>) since we flattened it from <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">28,</span> <span class="pre">28)</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">784)</span></code>.</p>
<p>How about the <code class="docutils literal notranslate"><span class="pre">(10x10)</span></code>?</p>
<p>These values come from the parameters we set in our <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layers, <code class="docutils literal notranslate"><span class="pre">in_features=10</span></code> and <code class="docutils literal notranslate"><span class="pre">out_features=10</span></code> or <code class="docutils literal notranslate"><span class="pre">nn.Linear(in_features=10,</span> <span class="pre">out_features=10)</span></code>.</p>
<p>What was the first rule of matrix multiplication again?</p>
<ol class="arabic simple">
<li><p>The <strong>inner dimensions</strong> must match.</p></li>
</ol>
<p>Right!</p>
<p>So what happens if we change <code class="docutils literal notranslate"><span class="pre">in_features=10</span></code> to <code class="docutils literal notranslate"><span class="pre">in_features=784</span></code> in the first layer?</p>
<p>Let’s find out!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Flatten the input as well as make sure the first layer can accept the flattened input shape</span>
<span class="n">model_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="c1"># &lt;-- NEW: change in_features=10 to in_features=784</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model</span>
<span class="n">model_2</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-0.2045,  0.2677, -0.0713, -0.3096, -0.0586,  0.3153, -0.3413,  0.2031,
          0.4421,  0.1715]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>It worked!</p>
<p>We got an output from our model!</p>
<p>The output might not mean much for now but at least we know all of the shapes line up and data can flow all the through our model.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code> layer turned our input image from <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">28,</span> <span class="pre">28)</span></code> to <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">784)</span></code> and our first <code class="docutils literal notranslate"><span class="pre">nn.Linear(in_features=784,</span> <span class="pre">out_features=10)</span></code> layer could accept it as input.</p>
</section>
<section id="incorrect-hidden-layer-input-and-output-shapes">
<h3>1.6 Incorrect hidden layer input and output shapes<a class="headerlink" href="#incorrect-hidden-layer-input-and-output-shapes" title="Permalink to this heading">#</a></h3>
<p>What happens if our input layer(s) had the correct shapes but there was a mismatch between the interconnected layer(s)?</p>
<p>As in, our first <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> had <code class="docutils literal notranslate"><span class="pre">out_features=10</span></code> but the next <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> had <code class="docutils literal notranslate"><span class="pre">in_features=5</span></code>.</p>
<p>This is an example of <strong>incorrect input and output shapes between layers</strong>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a model with incorrect input and output shapes between layers</span>
<span class="n">model_3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="c1"># out_features=10 </span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># &lt;-- NEW: in_features does not match the out_features of the previous layer</span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model (this will error)</span>
<span class="n">model_3</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [15],</span> in <span class="ni">&lt;cell line: 9&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">model_3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> <span class="c1"># out_features=10 </span>
<span class="g g-Whitespace">      </span><span class="mi">5</span>     <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># &lt;-- NEW: in_features does not match the out_features of the previous layer</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> <span class="c1"># Pass the image through the model (this will error)</span>
<span class="ne">----&gt; </span><span class="mi">9</span> <span class="n">model_3</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (1x10 and 5x10)
</pre></div>
</div>
</div>
</div>
<p>Running the model above we get the following error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">linear</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="mi">112</span> 
    <span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="o">--&gt;</span> <span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="mi">115</span> 
    <span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">1</span><span class="n">x10</span> <span class="ow">and</span> <span class="mi">5</span><span class="n">x10</span><span class="p">)</span>
</pre></div>
</div>
<p>Once again, we’ve broken rule 1 of matrix multiplication, the <strong>inner dimensions</strong> must match.</p>
<p>Our first <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layer outputs a shape of <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">10)</span></code> but our second <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layer is expecting a shape of <code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">5)</span></code>.</p>
<p>How could we fix this?</p>
<p>Well, we could set <code class="docutils literal notranslate"><span class="pre">in_features=10</span></code> for the second <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> manually, or we could try one of the newer features of PyTorch, “lazy” layers.</p>
</section>
<section id="pytorch-lazy-layers-automatically-inferring-the-input-shape">
<h3>1.7 PyTorch lazy layers (automatically inferring the input shape)<a class="headerlink" href="#pytorch-lazy-layers-automatically-inferring-the-input-shape" title="Permalink to this heading">#</a></h3>
<p>Lazy layers in PyTorch often come in the form of <code class="docutils literal notranslate"><span class="pre">nn.LazyX</span></code> where <code class="docutils literal notranslate"><span class="pre">X</span></code> is an existing non-lazy form of the layer.</p>
<p>For example, the lazy equilvalent of <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> is <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.LazyLinear.html"><code class="docutils literal notranslate"><span class="pre">nn.LazyLinear()</span></code></a>.</p>
<p>The main feature of a <code class="docutils literal notranslate"><span class="pre">Lazy</span></code> layer is to <em>infer</em> what the <code class="docutils literal notranslate"><span class="pre">in_features</span></code> or input shape from the previous layer should be.</p>
<blockquote>
<div><p><strong>Note:</strong> As of November 2022, <code class="docutils literal notranslate"><span class="pre">Lazy</span></code> layers in PyTorch are still experimental and subject to change, however their usage shouldn’t differ too dramatically from what’s below.</p>
</div></blockquote>
<p>For example, if the previous layer has <code class="docutils literal notranslate"><span class="pre">out_features=10</span></code>, the subsequent <code class="docutils literal notranslate"><span class="pre">Lazy</span></code> layer should infer that <code class="docutils literal notranslate"><span class="pre">in_features=10</span></code>.</p>
<p>Let’s test it out.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Try nn.LazyLinear() as the second layer</span>
<span class="n">model_4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># &lt;-- NEW: no in_features parameter as this is inferred from the previous layer&#39;s output</span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model</span>
<span class="n">model_4</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/daniel/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.
  warnings.warn(&#39;Lazy modules are a new feature under heavy development &#39;
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.4282,  0.2492, -0.2045, -0.4943, -0.1639,  0.1166,  0.3828, -0.1283,
         -0.1771, -0.2277]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>It works (though there may be a warning depending on the version of PyTorch you’re using, if so, don’t worry, it’s just to say the <code class="docutils literal notranslate"><span class="pre">Lazy</span></code> layers are still in development)!</p>
<p>How about we try replacing all the <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code> layers with <code class="docutils literal notranslate"><span class="pre">nn.LazyLinear()</span></code> layers?</p>
<p>Then we’ll only have to set the <code class="docutils literal notranslate"><span class="pre">out_features</span></code> values for each.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Replace all nn.Linear() layers with nn.LazyLinear()</span>
<span class="n">model_5</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># &lt;-- NEW </span>
<span class="p">)</span>

<span class="c1"># Pass the image through the model</span>
<span class="n">model_5</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.1375, -0.2175, -0.1054,  0.1424, -0.1406, -0.1180, -0.0896, -0.4285,
         -0.0077, -0.3188]], grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Nice!</p>
<p>It worked again, our image was able to flow through the network without any issues.</p>
<blockquote>
<div><p><strong>Note:</strong> The above examples only deal with one type of layer in PyTorch, <code class="docutils literal notranslate"><span class="pre">nn.Linear()</span></code>, however, the principles of lining up input and output shapes with each layer is a constant throughout all neural networks and different types of data.</p>
<p>Layers like <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code class="docutils literal notranslate"><span class="pre">nn.Conv2d()</span></code></a>, used in convolutional neural networks (CNNs) can even accept inputs without the use of <code class="docutils literal notranslate"><span class="pre">nn.Flatten()</span></code>. You can see more on this in <a class="reference external" href="https://www.learnpytorch.io/03_pytorch_computer_vision/#7-model-2-building-a-convolutional-neural-network-cnn">03. PyTorch Computer Vision section 7: Building a CNN</a>.</p>
</div></blockquote>
</section>
</section>
<section id="device-errors-in-pytorch">
<h2>2. Device errors in PyTorch<a class="headerlink" href="#device-errors-in-pytorch" title="Permalink to this heading">#</a></h2>
<p>One of the main benefits of PyTorch is the in-built ability for doing computations on a GPU (graphics processing unit).</p>
<p>GPUs can often perform operations, specifically matrix multiplications (which make up the most of neural networks) much faster than CPUs (central processing units).</p>
<p>If you’re using vanilla PyTorch (no other external libraries), PyTorch requires you to explicitly set which device you’re computing on.</p>
<p>For example, to send your model to a target <code class="docutils literal notranslate"><span class="pre">device</span></code>, you would use the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.to.html"><code class="docutils literal notranslate"><span class="pre">to()</span></code></a> method, such as <code class="docutils literal notranslate"><span class="pre">model.to(device)</span></code>.</p>
<p>And similarly for data <code class="docutils literal notranslate"><span class="pre">some_dataset.to(device)</span></code>.</p>
<p><strong>Device errors</strong> occur when your model/data are on different devices.</p>
<p>Such as when you’ve sent your model to the target GPU device but your data is still on the CPU.</p>
<section id="setting-the-target-device">
<h3>2.1 Setting the target device<a class="headerlink" href="#setting-the-target-device" title="Permalink to this heading">#</a></h3>
<p>Let’s set our current device to <code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code> if it’s available.</p>
<blockquote>
<div><p><strong>Note:</strong> See <a class="reference external" href="https://www.learnpytorch.io/00_pytorch_fundamentals/#running-tensors-on-gpus-and-making-faster-computations">00. PyTorch Fundamentals: Running Tensors on GPUs</a> for more information about how to get access to a GPU and set it up with PyTorch.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># Set device to &quot;cuda&quot; if it&#39;s available otherwise default to &quot;cpu&quot;</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Current device: cuda
</pre></div>
</div>
</div>
</div>
<p>Now let’s create a model with the same layers as <code class="docutils literal notranslate"><span class="pre">model_5</span></code>.</p>
<p>In PyTorch, models and tensors are created on the CPU by default.</p>
<p>We can test this by checking the <code class="docutils literal notranslate"><span class="pre">device</span></code> attribute of the model we create.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="c1"># Create a model (similar to model_5 above)</span>
<span class="n">model_6</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span> 
    <span class="n">nn</span><span class="o">.</span><span class="n">LazyLinear</span><span class="p">(</span><span class="n">out_features</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># All models and tensors are created on the CPU by default (unless explicitly set otherwise)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model is on device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="n">model_6</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model is on device: cpu
</pre></div>
</div>
</div>
</div>
</section>
<section id="preparing-data-for-modelling">
<h3>2.2 Preparing data for modelling<a class="headerlink" href="#preparing-data-for-modelling" title="Permalink to this heading">#</a></h3>
<p>To prepare our data for modelling, let’s create some PyTorch <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>’s.</p>
<p>To make things quicker, we’ll use an instance of <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler"><code class="docutils literal notranslate"><span class="pre">torch.utils.data.RandomSampler</span></code></a> to randomly select 10% of the training and testing samples (we’re not interested in the best performing model as much as we are in showcasing potential errors).</p>
<p>We’ll also setup a loss function of <code class="docutils literal notranslate"><span class="pre">torch.nn.CrossEntropyLoss()</span></code> as well as an optimizer of <code class="docutils literal notranslate"><span class="pre">torch.optim.SGD(lr=0.01)</span></code>.</p>
<blockquote>
<div><p><strong>Note:</strong> For more information on preparing data, loss functions and optimizers for training a PyTorch model, see <a class="reference external" href="https://www.learnpytorch.io/01_pytorch_workflow/#3-train-model">01. PyTorch Workflow Fundamentals section 3: Training a model</a>.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">RandomSampler</span>

<span class="c1"># Only sample 10% of the data</span>
<span class="n">train_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> 
                              <span class="n">num_samples</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)))</span>

<span class="n">test_sampler</span> <span class="o">=</span> <span class="n">RandomSampler</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> 
                             <span class="n">num_samples</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of random training samples selected: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of random testing samples selected: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Create DataLoaders and turn data into batches</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span>
                              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                              <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">)</span>

<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>
                             <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                             <span class="n">sampler</span><span class="o">=</span><span class="n">test_sampler</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of batches in train_dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2"> batches of size </span><span class="si">{</span><span class="n">BATCH_SIZE</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of batches in test_dataloader: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">)</span><span class="si">}</span><span class="s2"> batch of size </span><span class="si">{</span><span class="n">BATCH_SIZE</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Create loss function</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Create optimizer</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> 
                            <span class="n">params</span><span class="o">=</span><span class="n">model_6</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of random training samples selected: 6000/60000
Number of random testing samples selected: 1000/10000
Number of batches in train_dataloader: 188 batches of size 32
Number of batches in test_dataloader: 32 batch of size 32
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-a-model-on-the-cpu">
<h3>2.3 Training a model on the CPU<a class="headerlink" href="#training-a-model-on-the-cpu" title="Permalink to this heading">#</a></h3>
<p>Data ready, model ready, let’s train!</p>
<p>We’ll use a standard PyTorch training loop to do five epochs of training with <code class="docutils literal notranslate"><span class="pre">model_6</span></code> going over 10% of the data.</p>
<p>Don’t worry too much here about the loss being as low as it could be as we’re more focused on making sure there aren’t any errors than having the lowest possible loss.</p>
<img alt="annotated pytorch training loop steps" src="https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/01-pytorch-training-loop-annotated.png" />
<blockquote>
<div><p><strong>Note:</strong> For more information on the steps in a PyTorch training loop, see <a class="reference external" href="https://www.learnpytorch.io/01_pytorch_workflow/#pytorch-training-loop">01. PyTorch Workflow section 3: PyTorch training loop</a>.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Set the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Train the model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>

    <span class="c1"># Set loss to 0 every epoch</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Get images (X) and labels (y)</span>
    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>

        <span class="c1"># Forward pass</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Calculate the loss</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span>

        <span class="c1"># Optimizer zero grad</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># Loss backward</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Optimizer step</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  
    <span class="c1"># Print loss in the epoch loop only</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> | Training loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "28ec173850c84277a11540fc3cd0350f", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 0 | Training loss: 334.65
Epoch: 1 | Training loss: 215.44
Epoch: 2 | Training loss: 171.15
Epoch: 3 | Training loss: 154.72
Epoch: 4 | Training loss: 142.22
</pre></div>
</div>
</div>
</div>
<p>Nice! Looks like our training loop is working!</p>
<p>Our model’s loss is going down (the lower the loss the better).</p>
</section>
<section id="attempting-to-train-a-model-on-the-gpu-with-errors">
<h3>2.4 Attempting to train a model on the GPU (with errors)<a class="headerlink" href="#attempting-to-train-a-model-on-the-gpu-with-errors" title="Permalink to this heading">#</a></h3>
<p>Now let’s send our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> to the target <code class="docutils literal notranslate"><span class="pre">device</span></code> (in our case, this is a <code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code> GPU).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Send model_6 to the target device (&quot;cuda&quot;)</span>
<span class="n">model_6</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Print out what device the model is on</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model is on device: </span><span class="si">{</span><span class="nb">next</span><span class="p">(</span><span class="n">model_6</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model is on device: cuda:0
</pre></div>
</div>
</div>
</div>
<p>Our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> is on the <code class="docutils literal notranslate"><span class="pre">&quot;cuda:0&quot;</span></code> (where <code class="docutils literal notranslate"><span class="pre">0</span></code> is the index of the device, in case there was more than one GPU) device.</p>
<p>Now let’s run the same training loop code as above and see what happens.</p>
<p>Can you guess?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># Set the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Train the model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>

  <span class="c1"># Set loss to 0 every epoch</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># Get images (X) and labels (y)</span>
  <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>

    <span class="c1"># Forward pass</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># model is on GPU, data is on CPU (will error)</span>

    <span class="c1"># Calculate the loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span>
    
    <span class="c1"># Optimizer zero grad</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Loss backward</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Optimizer step</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  
  <span class="c1"># Print loss in the epoch loop only</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> | Training loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "75606965bc224a6a8b223db95612e24e", "version_major": 2, "version_minor": 0}</script><div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [24],</span> in <span class="ni">&lt;cell line: 7&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">12</span> <span class="c1"># Get images (X) and labels (y)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span> <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span> 
<span class="g g-Whitespace">     </span><span class="mi">15</span>   <span class="c1"># Forward pass</span>
<span class="ne">---&gt; </span><span class="mi">16</span>   <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># model is on GPU, data is on CPU (will error)</span>
<span class="g g-Whitespace">     </span><span class="mi">18</span>   <span class="c1"># Calculate the loss</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span>   <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)
</pre></div>
</div>
</div>
</div>
<p>Whoops!</p>
<p>Looks like we go a device error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py in forward(self, input)
    112 
    113     def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114         return F.linear(input, self.weight, self.bias)
    115 
    116     def extra_repr(self) -&gt; str:

RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)
</pre></div>
</div>
<p>We can see the error states <code class="docutils literal notranslate"><span class="pre">Expected</span> <span class="pre">all</span> <span class="pre">tensors</span> <span class="pre">to</span> <span class="pre">be</span> <span class="pre">on</span> <span class="pre">the</span> <span class="pre">same</span> <span class="pre">device,</span> <span class="pre">but</span> <span class="pre">found</span> <span class="pre">at</span> <span class="pre">least</span> <span class="pre">two</span> <span class="pre">devices,</span> <span class="pre">cuda:0</span> <span class="pre">and</span> <span class="pre">cpu!</span></code>.</p>
<p>In essence, our model is on the <code class="docutils literal notranslate"><span class="pre">cuda:0</span></code> device but our data tensors (<code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>) are still on the <code class="docutils literal notranslate"><span class="pre">cpu</span></code> device.</p>
<p>But <strong>PyTorch expects <em>all</em> tensors to be on the same device</strong>.</p>
</section>
<section id="training-a-model-on-the-gpu-without-errors">
<h3>2.5 Training a model on the GPU (without errors)<a class="headerlink" href="#training-a-model-on-the-gpu-without-errors" title="Permalink to this heading">#</a></h3>
<p>Let’s fix this error but sending our data tensors (<code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>) to the target <code class="docutils literal notranslate"><span class="pre">device</span></code> as well.</p>
<p>We can do so using <code class="docutils literal notranslate"><span class="pre">X.to(device)</span></code> and <code class="docutils literal notranslate"><span class="pre">y.to(device)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Send the model to the target device (we don&#39;t need to do this again but we will for completeness)</span>
<span class="n">model_6</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Set the number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Train the model</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>

  <span class="c1"># Set loss to 0 every epoch</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1"># Get images (X) and labels (y)</span>
  <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">train_dataloader</span><span class="p">:</span>

    <span class="c1"># Put target data on target device  &lt;-- NEW</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="c1"># &lt;-- NEW: send data to target device</span>

    <span class="c1"># Forward pass</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="c1"># Calculate the loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span>
    
    <span class="c1"># Optimizer zero grad</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Loss backward</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="c1"># Optimizer step</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  
  <span class="c1"># Print loss in the epoch loop only</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> | Training loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "3f94f47483b84c0ca344c1c3545a9d04", "version_major": 2, "version_minor": 0}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 0 | Training loss: 134.76
Epoch: 1 | Training loss: 127.76
Epoch: 2 | Training loss: 120.85
Epoch: 3 | Training loss: 120.50
Epoch: 4 | Training loss: 116.29
</pre></div>
</div>
</div>
</div>
<p>Excellent!</p>
<p>Our training loop completes just as before because now both our model <em>and</em> data tensors are on the same device.</p>
<blockquote>
<div><p><strong>Note:</strong> Libraries like <a class="reference external" href="https://github.com/huggingface/accelerate">HuggingFace Accelerate</a> are a fantastic way to train your PyTorch models with minimal explicit device setting (they discover the best device to use and set things up for you).</p>
<p>You could also write functions to ensure your training code happens all on the same device, see <a class="reference external" href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">05. PyTorch Going Modular section 4: Creating training functions</a> for more.</p>
</div></blockquote>
</section>
<section id="device-errors-when-making-predictions">
<h3>2.6 Device errors when making predictions<a class="headerlink" href="#device-errors-when-making-predictions" title="Permalink to this heading">#</a></h3>
<p>We’ve seen device errors whilst training but the same error can occur during testing or inference (making predictions).</p>
<p>The whole idea of training a model on some data is to use it to make predictions on <em>unseen</em> data.</p>
<p>Let’s take our trained <code class="docutils literal notranslate"><span class="pre">model_6</span></code> and use it to make a prediction on a sample from the test dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a single sample from the test dataset</span>
<span class="n">test_image</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">test_data</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test image shape: </span><span class="si">{</span><span class="n">test_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test image label: </span><span class="si">{</span><span class="n">test_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test image shape: torch.Size([28, 28])
Test image label: 9
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot test image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">class_names</span><span class="p">[</span><span class="n">test_label</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/2726b7a737a93d6160eacd417b6f3feeec560ae9ce4916b8e2bdeab9b20b150f.png" src="../../../_images/2726b7a737a93d6160eacd417b6f3feeec560ae9ce4916b8e2bdeab9b20b150f.png" />
</div>
</div>
<p>Looking good!</p>
<p>Now let’s try to make a prediction on it by passing it to our <code class="docutils literal notranslate"><span class="pre">model_6</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pass the test image through model_6 to make a prediction</span>
<span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [28],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Pass the test image through model_6 to make a prediction</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="p">)</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)
</pre></div>
</div>
</div>
</div>
<p>Dam!</p>
<p>We get another device error.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py in forward(self, input)
    112 
    113     def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 114         return F.linear(input, self.weight, self.bias)
    115 
    116     def extra_repr(self) -&gt; str:

RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)
</pre></div>
</div>
<p>This is because our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> is on the GPU (<code class="docutils literal notranslate"><span class="pre">&quot;cuda&quot;</span></code>), however, our <code class="docutils literal notranslate"><span class="pre">test_image</span></code> is on the CPU (in PyTorch, all tensors are on the CPU by default).</p>
<p>Let’s send the <code class="docutils literal notranslate"><span class="pre">test_image</span></code> to the target <code class="docutils literal notranslate"><span class="pre">device</span></code> and then try the prediction again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Send test_image to target device</span>
<span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [30],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Send test_image to target device</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x10)
</pre></div>
</div>
</div>
</div>
<p>Oh no! Another error…</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">linear</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="mi">112</span> 
    <span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="o">--&gt;</span> <span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="mi">115</span> 
    <span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">mat1</span> <span class="ow">and</span> <span class="n">mat2</span> <span class="n">shapes</span> <span class="n">cannot</span> <span class="n">be</span> <span class="n">multiplied</span> <span class="p">(</span><span class="mi">28</span><span class="n">x28</span> <span class="ow">and</span> <span class="mi">784</span><span class="n">x10</span><span class="p">)</span>
</pre></div>
</div>
<p>This time it’s a shape error.</p>
<p>We’ve seen these before.</p>
<p>What’s going on with our <code class="docutils literal notranslate"><span class="pre">test_image</span></code> shape?</p>
<p>Perhaps it’s because our model was trained on images that had a batch dimension?</p>
<p>And our current <code class="docutils literal notranslate"><span class="pre">test_image</span></code> doesn’t have a batch dimension?</p>
<p>Here’s another helpful rule of thumb to remember: <strong>trained models like to predict on data in the same format and shape that they were trained on</strong>.</p>
<p>This means if our model was trained on images with a batch dimension, it’ll tend to like to predict on images with a batch dimension, even if the batch dimension is only 1 (a single sample).</p>
<p>And if our model was trained on data in the format <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> (or another format), it’ll like to predict on data in that same format (we’ll see this later on).</p>
<p>We can add a single batch dimension to our <code class="docutils literal notranslate"><span class="pre">test_image</span></code> using the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.unsqueeze.html"><code class="docutils literal notranslate"><span class="pre">torch.unsqueeze()</span></code></a> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Changing the input size to be the same as what the model was trained on</span>
<span class="n">original_input_shape</span> <span class="o">=</span> <span class="n">test_image</span><span class="o">.</span><span class="n">shape</span>
<span class="n">updated_input_shape</span> <span class="o">=</span> <span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># adding a batch dimension on the &quot;0th&quot; dimension</span>

<span class="c1"># Print out shapes of original tensor and updated tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original input data shape: </span><span class="si">{</span><span class="n">original_input_shape</span><span class="si">}</span><span class="s2"> -&gt; [height, width]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Updated input data shape (with added batch dimension): </span><span class="si">{</span><span class="n">updated_input_shape</span><span class="si">}</span><span class="s2"> -&gt; [batch, height, width]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original input data shape: torch.Size([28, 28]) -&gt; [height, width]
Updated input data shape (with added batch dimension): torch.Size([1, 28, 28]) -&gt; [batch, height, width]
</pre></div>
</div>
</div>
</div>
<p>Nice!</p>
<p>We’ve found a way to add a batch dimension to our <code class="docutils literal notranslate"><span class="pre">test_image</span></code>.</p>
<p>Let’s try make a prediction on it again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make prediction on test image with additional batch size dimension and with it on the target device</span>
<span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="nn">Input In [32],</span> in <span class="ni">&lt;cell line: 2&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="c1"># Make prediction on test image with additional batch size dimension and with it on the target device</span>
<span class="ne">----&gt; </span><span class="mi">2</span> <span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/container.py:139,</span> in <span class="ni">Sequential.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">139</span>         <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>     <span class="k">return</span> <span class="nb">input</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/module.py:1130,</span> in <span class="ni">Module._call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1126</span> <span class="c1"># If we don&#39;t have any hooks, we want to skip the rest of the logic in</span>
<span class="g g-Whitespace">   </span><span class="mi">1127</span> <span class="c1"># this function, and just call forward.</span>
<span class="g g-Whitespace">   </span><span class="mi">1128</span> <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1129</span>         <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1130</span>     <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1131</span> <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1132</span> <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">File ~/code/pytorch/env/lib/python3.8/site-packages/torch/nn/modules/linear.py:114,</span> in <span class="ni">Linear.forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">113</span> <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>     <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

<span class="ne">RuntimeError</span>: expected scalar type Float but found Byte
</pre></div>
</div>
</div>
</div>
<p>What?</p>
<p>Another error!</p>
<p>This time it’s a datatype error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python3</span><span class="mf">.7</span><span class="o">/</span><span class="n">dist</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">torch</span><span class="o">/</span><span class="n">nn</span><span class="o">/</span><span class="n">modules</span><span class="o">/</span><span class="n">linear</span><span class="o">.</span><span class="n">py</span> <span class="ow">in</span> <span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="mi">112</span> 
    <span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="o">--&gt;</span> <span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
    <span class="mi">115</span> 
    <span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">expected</span> <span class="n">scalar</span> <span class="nb">type</span> <span class="n">Float</span> <span class="n">but</span> <span class="n">found</span> <span class="n">Byte</span>
</pre></div>
</div>
<p>We’ve stumbled upon the third most common error in PyTorch, datatype errors.</p>
<p>Let’s figure out how to fix them in the next section.</p>
</section>
</section>
<section id="datatype-errors-in-pytorch">
<h2>3. Datatype errors in PyTorch<a class="headerlink" href="#datatype-errors-in-pytorch" title="Permalink to this heading">#</a></h2>
<p>Recall the rule of thumb: <strong>trained models like to predict on data that’s in the same shape and format that they were trained on</strong>.</p>
<p>It looks like our model expects a <code class="docutils literal notranslate"><span class="pre">Float</span></code> datatype but our <code class="docutils literal notranslate"><span class="pre">test_image</span></code> is in <code class="docutils literal notranslate"><span class="pre">Byte</span></code> datatype.</p>
<p>We can tell this by the last line in the previous error:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">expected</span> <span class="n">scalar</span> <span class="nb">type</span> <span class="n">Float</span> <span class="n">but</span> <span class="n">found</span> <span class="n">Byte</span>
</pre></div>
</div>
<p>Why is this?</p>
<p>It’s because our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> was trained on data samples in the format of <code class="docutils literal notranslate"><span class="pre">Float</span></code>, specifically, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>.</p>
<p>How do we know this?</p>
<p>Well, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> is the default for many tensors in PyTorch, unless explicitly set otherwise.</p>
<p>But let’s do a check to make sure.</p>
<section id="checking-the-datatype-of-the-data-the-model-was-trained-on">
<h3>3.1 Checking the datatype of the data the model was trained on<a class="headerlink" href="#checking-the-datatype-of-the-data-the-model-was-trained-on" title="Permalink to this heading">#</a></h3>
<p>We can check the datatype of the data our model was trained on by looking at the <code class="docutils literal notranslate"><span class="pre">dtype</span></code> attribute of a sample from our <code class="docutils literal notranslate"><span class="pre">train_dataloader</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get a single sample from the train_dataloader and print the dtype</span>
<span class="n">train_image_batch</span><span class="p">,</span> <span class="n">train_label_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">))</span>
<span class="n">train_image_single</span><span class="p">,</span> <span class="n">train_label_single</span> <span class="o">=</span> <span class="n">train_image_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">train_label_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Print the datatype of the train_image_single</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Datatype of training data: </span><span class="si">{</span><span class="n">train_image_single</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Datatype of training data: torch.float32
</pre></div>
</div>
</div>
</div>
<p>There we go! We confirmed our training data samples are in <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>.</p>
<p>So it makes sense that our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> wants to predict on this datatype.</p>
<p>But how did our training data get in that datatype?</p>
<p>It happened back in section 1.3 when we downloaded the Fashion MNIST dataset and used the <code class="docutils literal notranslate"><span class="pre">transform</span></code> parameter of <a class="reference external" href="https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html"><code class="docutils literal notranslate"><span class="pre">torchvision.transforms.ToTensor()</span></code></a>.</p>
<p>This <code class="docutils literal notranslate"><span class="pre">transform</span></code> converts whatever data is passed to it into a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> with the <em>default</em> datatype <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code>.</p>
<p>So another rule of thumb: <strong>when making predictions, whatever transforms you performed on the training data, you should also perform on the testing data</strong>.</p>
</section>
<section id="changing-the-datatype-of-a-tensor">
<h3>3.2 Changing the datatype of a tensor<a class="headerlink" href="#changing-the-datatype-of-a-tensor" title="Permalink to this heading">#</a></h3>
<p>In our case, we could create a standalone transform to transform our test data but we can also change the datatype of a target tensor with <code class="docutils literal notranslate"><span class="pre">tensor.type(some_type_here)</span></code>, for example, <code class="docutils literal notranslate"><span class="pre">tensor_1.type(torch.float32)</span></code>.</p>
<p>Let’s try it out.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Print out the original datatype of test_image</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original datatype: </span><span class="si">{</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Change the datatype of test_image and see the change</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Changing the datatype: </span><span class="si">{</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original datatype: torch.uint8
Changing the datatype: torch.float32
</pre></div>
</div>
</div>
</div>
</section>
<section id="making-predictions-on-a-test-image-and-making-sure-its-in-the-right-format">
<h3>3.3 Making predictions on a test image and making sure it’s in the right format<a class="headerlink" href="#making-predictions-on-a-test-image-and-making-sure-its-in-the-right-format" title="Permalink to this heading">#</a></h3>
<p>Alright, it looks like we’ve got all of the pieces of the puzzle ready, shape, device and datatype, let’s try and make a prediction!</p>
<blockquote>
<div><p><strong>Note:</strong> Remember a model likes to make predictions on data in the same (or similar) format to what it was trained on (shape, device and datatype).</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a prediction with model_6 on the transformed test_image</span>
<span class="n">pred_on_gpu</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># add a batch dimension</span>
                      <span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="c1"># convert the datatype to torch.float32</span>
                      <span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span> <span class="c1"># send the tensor to the target device</span>
<span class="n">pred_on_gpu</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ -963.8352, -1658.8182,  -735.9952, -1285.2964,  -550.3845,   949.4190,
          -538.1960,  1123.0616,   552.7371,  1413.8110]], device=&#39;cuda:0&#39;,
       grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Woohoo!!!</p>
<p>A fair few steps but our <code class="docutils literal notranslate"><span class="pre">model_6</span></code> successfully makes a prediction on <code class="docutils literal notranslate"><span class="pre">test_image</span></code>.</p>
<p>Since <code class="docutils literal notranslate"><span class="pre">test_image</span></code> is on the CPU by default, we could also put the model back on the CPU using the <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html"><code class="docutils literal notranslate"><span class="pre">.cpu()</span></code> method</a> and make the same prediction on the CPU device instead of the GPU device.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Put model back on CPU</span>
<span class="n">model_6</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
 
<span class="c1"># Make a prediction on the CPU device (no need to put test_image on the CPU as it&#39;s already there)</span>
<span class="n">pred_on_cpu</span> <span class="o">=</span> <span class="n">model_6</span><span class="p">(</span><span class="n">test_image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># add a batch dimension</span>
                      <span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span> <span class="c1"># convert the datatype to torch.float32 </span>
<span class="n">pred_on_cpu</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ -963.8351, -1658.8182,  -735.9953, -1285.2964,  -550.3845,   949.4189,
          -538.1960,  1123.0615,   552.7371,  1413.8110]],
       grad_fn=&lt;AddmmBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>And again the prediction works!</p>
<p>Is it correct?</p>
<p>We can check by the taking the model’s raw outputs and converting them from <code class="docutils literal notranslate"><span class="pre">raw</span> <span class="pre">logits</span> <span class="pre">-&gt;</span> <span class="pre">prediction</span> <span class="pre">probabilities</span> <span class="pre">-&gt;</span> <span class="pre">prediction</span> <span class="pre">label</span></code> (see <a class="reference external" href="https://www.learnpytorch.io/02_pytorch_classification/#31-going-from-raw-model-outputs-to-predicted-labels-logits-prediction-probabilities-prediction-labels">02. PyTorch Neural Network Classification section 3.1</a> for more on this conversion).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert raw logits to prediction probabilities</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">pred_on_cpu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Convert prediction probabilities to prediction label</span>
<span class="n">pred_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Check if it&#39;s correct</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test label: </span><span class="si">{</span><span class="n">test_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pred label: </span><span class="si">{</span><span class="n">pred_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Is the prediction correct? </span><span class="si">{</span><span class="n">pred_label</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">test_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test label: 9
Pred label: tensor([9])
Is the prediction correct? True
</pre></div>
</div>
</div>
</div>
<p>There can a fair few steps involved when making predictions on a test or custom sample.</p>
<p>So one of the ways to prevent repeating all of these steps is to turn them into a function.</p>
<p>There’s an example of this in <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function">04. PyTorch Custom Datasets section 11.3: Building a function to predict on custom images</a>.</p>
</section>
</section>
<section id="putting-it-all-together">
<h2>Putting it all together<a class="headerlink" href="#putting-it-all-together" title="Permalink to this heading">#</a></h2>
<p>We’ve been hands on with three of the main errors you’ll come across when building neural networks with PyTorch:</p>
<ol class="arabic simple">
<li><p><strong>Shape errors</strong> - there are mismatches between the data you’re working with the neural network you’re building to find patterns in or there are mismatches between the connecting layers of your neural network.</p></li>
<li><p><strong>Device errors</strong> - your model and data are on different devices, PyTorch expects <em>all</em> tensors and objects to be on the <em>same</em> device.</p></li>
<li><p><strong>Datatype errors</strong> - you’re trying to compute on one datatype when your model expects another datatype.</p></li>
</ol>
<p>And we’ve seen how and why they occur and then how to fix them:</p>
<ul class="simple">
<li><p>Your model wants to make predictions on same kind of data it was trained on (shape, device and datatype).</p></li>
<li><p>Your model and data should be on same device for training and testing.</p></li>
<li><p>You can take care of many of these issues by creating reusable functions that define <code class="docutils literal notranslate"><span class="pre">device</span></code> and datatype, such as in <a class="reference external" href="https://www.learnpytorch.io/05_pytorch_going_modular/#4-creating-train_step-and-test_step-functions-and-train-to-combine-them">04. PyTorch Going Modular section 4: Creating training and testing functions</a>.</p></li>
</ul>
<p>Knowing about these errors won’t prevent you from making them in the future but it will give you an idea of where to go to fix them.</p>
<p>For more in-depth examples of these errors, including making them and fixing in a hands-on manner, check out the <a class="reference external" href="https://dbourke.link/ZTMPyTorch">Zero to Mastery: PyTorch for Deep Learning course</a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebook/pytorch_deep_learning/extras"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="pytorch_cheatsheet.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">PyTorch Cheatsheet</p>
      </div>
    </a>
    <a class="right-next"
       href="pytorch_setup.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Setup to code PyTorch</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-errors-in-pytorch">1. Shape errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-multiplication-shape-errors">1.1 Matrix multiplication shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-neural-network-shape-errors">1.2 PyTorch neural network shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#downloading-a-dataset">1.3 Downloading a dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#building-a-series-of-neural-networks-with-different-shape-errors">1.4 Building a series of neural networks with different shape errors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incorrect-input-layer-shapes">1.5 Incorrect input layer shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#incorrect-hidden-layer-input-and-output-shapes">1.6 Incorrect hidden layer input and output shapes</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-lazy-layers-automatically-inferring-the-input-shape">1.7 PyTorch lazy layers (automatically inferring the input shape)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#device-errors-in-pytorch">2. Device errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-the-target-device">2.1 Setting the target device</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#preparing-data-for-modelling">2.2 Preparing data for modelling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-model-on-the-cpu">2.3 Training a model on the CPU</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#attempting-to-train-a-model-on-the-gpu-with-errors">2.4 Attempting to train a model on the GPU (with errors)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-model-on-the-gpu-without-errors">2.5 Training a model on the GPU (without errors)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#device-errors-when-making-predictions">2.6 Device errors when making predictions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datatype-errors-in-pytorch">3. Datatype errors in PyTorch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#checking-the-datatype-of-the-data-the-model-was-trained-on">3.1 Checking the datatype of the data the model was trained on</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#changing-the-datatype-of-a-tensor">3.2 Changing the datatype of a tensor</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#making-predictions-on-a-test-image-and-making-sure-its-in-the-right-format">3.3 Making predictions on a test image and making sure it’s in the right format</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#putting-it-all-together">Putting it all together</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By thangckt
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>