

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>05. PyTorch Going Modular</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebook/pytorch_deep_learning/05_pytorch_going_modular';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="06. PyTorch Transfer Learning" href="06_pytorch_transfer_learning.html" />
    <link rel="prev" title="04. PyTorch Custom Datasets" href="04_pytorch_custom_datasets.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
  
  
    <p class="title logo__title"></p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Basic of ML &amp; DL</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../0_basic_MLDL/1_0_ml_overview.html">Machine Learning</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../0_basic_MLDL/1_1_ml_supervised_unsuppersives.html">Supervised vs. Unsuppervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="../0_basic_MLDL/1_2_regression.html">Regression &amp; Model Assessment</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../0_basic_MLDL/2_0_dl_overview.html">Deep Learning Overview</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../0_basic_MLDL/2_1_dl_neural_network.html">What is a neural network?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../0_basic_MLDL/2_2_layers.html">Standard Layers</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../0_basic_MLDL/3_1_workflow.html">Workflow in ML</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_basic_MLDL/3_2_Model_template.html">Core Ml templates</a></li>


</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">PyTorch for Deep Learning</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="00_overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="00_pytorch_fundamentals.html">00. PyTorch Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="01_pytorch_workflow.html">01. PyTorch Workflow Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="02_pytorch_classification.html">02. PyTorch Neural Network Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="03_pytorch_computer_vision.html">03. PyTorch Computer Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_pytorch_custom_datasets.html">04. PyTorch Custom Datasets</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">05. PyTorch Going Modular</a></li>
<li class="toctree-l1"><a class="reference internal" href="06_pytorch_transfer_learning.html">06. PyTorch Transfer Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_pytorch_experiment_tracking.html">07. PyTorch Experiment Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_pytorch_paper_replicating.html">08. PyTorch Paper Replicating</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_pytorch_model_deployment.html">09. PyTorch Model Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="extras/pytorch_extra_resources.html">PyTorch Extra Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="extras/pytorch_cheatsheet.html">PyTorch Cheatsheet</a></li>
<li class="toctree-l1"><a class="reference internal" href="extras/pytorch_most_common_errors.html">The Three Most Common Errors in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="extras/pytorch_setup.html">Setup to code PyTorch</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Zero to Mastery Machine Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../zero_to_mastery_ml/README.html">Zero to Mastery Machine Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Practices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_Practices/1_PT_Linear_Regression.html">Linear Regression</a></li>





<li class="toctree-l1"><a class="reference internal" href="../1_Practices/2_PT_Logistic_Regression.html">Logistic Regression</a></li>





</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/thangckt/note_ml/edit/main/notebook/pytorch_deep_learning/05_pytorch_going_modular.md" target="_blank"
   class="btn btn-sm btn-source-edit-button"
   title="Suggest edit"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>05. PyTorch Going Modular</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-going-modular">What is going modular?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-would-you-want-to-go-modular">Why would you want to go modular?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pros-and-cons-of-notebooks-vs-python-scripts">Pros and cons of notebooks vs Python scripts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#my-workflow">My workflow</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-in-the-wild">PyTorch in the wild</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-were-going-to-cover">What we’re going to cover</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-two-parts">Why two parts?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-were-working-towards">What we’re working towards</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#things-to-note">Things to note</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-get-help">Where can you get help?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-mode-vs-script-mode">0. Cell mode vs. script mode</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-data">1. Get data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-datasets-and-dataloaders-data-setup-py">2. Create Datasets and DataLoaders (<code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-a-model-model-builder-py">3. Making a model (<code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-train-step-and-test-step-functions-and-train-to-combine-them">4. Creating <code class="docutils literal notranslate"><span class="pre">train_step()</span></code> and <code class="docutils literal notranslate"><span class="pre">test_step()</span></code> functions and <code class="docutils literal notranslate"><span class="pre">train()</span></code> to combine them</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-function-to-save-the-model-utils-py">5. Creating a function to save the model (<code class="docutils literal notranslate"><span class="pre">utils.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-evaluate-and-save-the-model-train-py">6. Train, evaluate and save the model (<code class="docutils literal notranslate"><span class="pre">train.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extra-curriculum">Extra-curriculum</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p><a class="reference external" href="https://thangckt.github.io/pytorch_deep_learning/slides/05_pytorch_going_modular.pdf">View Slides</a></p>
<section class="tex2jax_ignore mathjax_ignore" id="pytorch-going-modular">
<h1>05. PyTorch Going Modular<a class="headerlink" href="#pytorch-going-modular" title="Permalink to this heading">#</a></h1>
<p>This section answers the question, “how do I turn my notebook code into Python scripts?”</p>
<p>To do so, we’re going to turn the most useful code cells in <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/">notebook 04. PyTorch Custom Datasets</a> into a series of Python scripts saved to a directory called <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular"><code class="docutils literal notranslate"><span class="pre">going_modular</span></code></a>.</p>
<section id="what-is-going-modular">
<h2>What is going modular?<a class="headerlink" href="#what-is-going-modular" title="Permalink to this heading">#</a></h2>
<p>Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality.</p>
<p>For example, we could turn our notebook code from a series of cells into the following Python files:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code> - a file to prepare and download data if needed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">engine.py</span></code> - a file containing various training functions.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code> or <code class="docutils literal notranslate"><span class="pre">model.py</span></code> - a file to create a PyTorch model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train.py</span></code> - a file to leverage all other files and train a target PyTorch model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">utils.py</span></code> - a file dedicated to helpful utility functions.</p></li>
</ul>
<blockquote>
<div><p><strong>Note:</strong> The naming and layout of the above files will depend on your use case and code requirements. Python scripts are as general as individual notebook cells, meaning, you could create one for almost any kind of functionality.</p>
</div></blockquote>
</section>
<section id="why-would-you-want-to-go-modular">
<h2>Why would you want to go modular?<a class="headerlink" href="#why-would-you-want-to-go-modular" title="Permalink to this heading">#</a></h2>
<p>Notebooks are fantastic for iteratively exploring and running experiments quickly.</p>
<p>However, for larger scale projects you may find Python scripts more reproducible and easier to run.</p>
<p>Though this is a debated topic, as companies like <a class="reference external" href="https://netflixtechblog.com/notebook-innovation-591ee3221233">Netflix have shown how they use notebooks for production code</a>.</p>
<p><strong>Production code</strong> is code that runs to offer a service to someone or something.</p>
<p>For example, if you have an app running online that other people can access and use, the code running that app is considered <strong>production code</strong>.</p>
<p>And libraries like <a class="reference external" href="http://fast.ai">fast.ai</a>’s <a class="reference external" href="https://github.com/fastai/nbdev"><code class="docutils literal notranslate"><span class="pre">nb-dev</span></code></a> (short for notebook development) enable you to write whole Python libraries (including documentation) with Jupyter Notebooks.</p>
<section id="pros-and-cons-of-notebooks-vs-python-scripts">
<h3>Pros and cons of notebooks vs Python scripts<a class="headerlink" href="#pros-and-cons-of-notebooks-vs-python-scripts" title="Permalink to this heading">#</a></h3>
<p>There’s arguments for both sides.</p>
<p>But this list sums up a few of the main topics.</p>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p><strong>Pros</strong></p></th>
<th class="head"><p><strong>Cons</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Notebooks</strong></p></td>
<td><p>Easy to experiment/get started</p></td>
<td><p>Versioning can be hard</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Easy to share (e.g. a link to a Google Colab notebook)</p></td>
<td><p>Hard to use only specific parts</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Very visual</p></td>
<td><p>Text and graphics can get in the way of code</p></td>
</tr>
</tbody>
</table>
</div>
<div class="pst-scrollable-table-container"><table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p><strong>Pros</strong></p></th>
<th class="head"><p><strong>Cons</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Python scripts</strong></p></td>
<td><p>Can package code together (saves rewriting similar code across different notebooks)</p></td>
<td><p>Experimenting isn’t as visual (usually have to run the whole script rather than one cell)</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Can use git for versioning</p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>Many open source projects use scripts</p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>Larger projects can be run on cloud vendors (not as much support for notebooks)</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="my-workflow">
<h3>My workflow<a class="headerlink" href="#my-workflow" title="Permalink to this heading">#</a></h3>
<p>I usually start machine learning projects in Jupyter/Google Colab notebooks for quick experimentation and visualization.</p>
<p>Then when I’ve got something working, I move the most useful pieces of code to Python scripts.</p>
<img alt="one possible workflow for writing machine learning code, start with jupyter or google colab notebooks and then move to Python scripts when you've got something working." src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/05-my-workflow-for-experimenting.png" />
<p><em>There are many possible workflows for writing machine learning code. Some prefer to start with scripts, others (like me) prefer to start with notebooks and go to scripts later on.</em></p>
</section>
<section id="pytorch-in-the-wild">
<h3>PyTorch in the wild<a class="headerlink" href="#pytorch-in-the-wild" title="Permalink to this heading">#</a></h3>
<p>In your travels, you’ll see many code repositories for PyTorch-based ML projects have instructions on how to run the PyTorch code in the form of Python scripts.</p>
<p>For example, you might be instructed to run code like the following in a terminal/command line to train a model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">MODEL_NAME</span> <span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span> <span class="o">--</span><span class="n">lr</span> <span class="n">LEARNING_RATE</span> <span class="o">--</span><span class="n">num_epochs</span> <span class="n">NUM_EPOCHS</span>
</pre></div>
</div>
<img alt="command line call for training a PyTorch model with different hyperparameters" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/05-python-train-command-line-annotated.png" />
<p><em>Running a PyTorch <code class="docutils literal notranslate"><span class="pre">train.py</span></code> script on the command line with various hyperparameter settings.</em></p>
<p>In this case, <code class="docutils literal notranslate"><span class="pre">train.py</span></code> is the target Python script, it’ll likely contain functions to train a PyTorch model.</p>
<p>And <code class="docutils literal notranslate"><span class="pre">--model</span></code>, <code class="docutils literal notranslate"><span class="pre">--batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">--lr</span></code> and <code class="docutils literal notranslate"><span class="pre">--num_epochs</span></code> are known as argument flags.</p>
<p>You can set these to whatever values you like and if they’re compatible with <code class="docutils literal notranslate"><span class="pre">train.py</span></code>, they’ll work, if not, they’ll error.</p>
<p>For example, let’s say we wanted to train our TinyVGG model from notebook 04 for 10 epochs with a batch size of 32 and a learning rate of 0.001:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">tinyvgg</span> <span class="o">--</span><span class="n">batch_size</span> <span class="mi">32</span> <span class="o">--</span><span class="n">lr</span> <span class="mf">0.001</span> <span class="o">--</span><span class="n">num_epochs</span> <span class="mi">10</span>
</pre></div>
</div>
<p>You could setup any number of these argument flags in your <code class="docutils literal notranslate"><span class="pre">train.py</span></code> script to suit your needs.</p>
<p>The PyTorch blog post for training state-of-the-art computer vision models uses this style.</p>
<img alt="PyTorch training script recipe for training state of the art computer vision models" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/05-training-sota-recipe.png" />
<p><em>PyTorch command line training script recipe for training state-of-the-art computer vision models with 8 GPUs. Source: <a class="reference external" href="https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/#the-training-recipe">PyTorch blog</a>.</em></p>
</section>
</section>
<section id="what-were-going-to-cover">
<h2>What we’re going to cover<a class="headerlink" href="#what-were-going-to-cover" title="Permalink to this heading">#</a></h2>
<p>The main concept of this section is: <strong>turn useful notebook code cells into reusable Python files.</strong></p>
<p>Doing this will save us writing the same code over and over again.</p>
<p>There are two notebooks for this section:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb"><strong>05. Going Modular: Part 1 (cell mode)</strong></a> - this notebook is run as a traditional Jupyter Notebook/Google Colab notebook and is a condensed version of <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/">notebook 04</a>.</p></li>
<li><p><a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb"><strong>05. Going Modular: Part 2 (script mode)</strong></a> - this notebook is the same as number 1 but with added functionality to turn each of the major sections into Python scripts, such as, <code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code> and <code class="docutils literal notranslate"><span class="pre">train.py</span></code>.</p></li>
</ol>
<p>The text in this document focuses on the code cells 05. Going Modular: Part 2 (script mode), the ones with <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">...</span></code> at the top.</p>
<section id="why-two-parts">
<h3>Why two parts?<a class="headerlink" href="#why-two-parts" title="Permalink to this heading">#</a></h3>
<p>Because sometimes the best way to learn something is to see how it <em>differs</em> from something else.</p>
<p>If you run each notebook side-by-side you’ll see how they differ and that’s where the key learnings are.</p>
<img alt="running cell mode notebook vs a script mode notebook" src="https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/05-notebook-cell-mode-vs-script-mode.png" />
<p><em>Running the two notebooks for section 05 side-by-side. You’ll notice that the <strong>script mode notebook has extra code cells</strong> to turn code from the cell mode notebook into Python scripts.</em></p>
</section>
<section id="what-were-working-towards">
<h3>What we’re working towards<a class="headerlink" href="#what-were-working-towards" title="Permalink to this heading">#</a></h3>
<p>By the end of this section we want to have two things:</p>
<ol class="arabic simple">
<li><p>The ability to train the model we built in notebook 04 (Food Vision Mini) with one line of code on the command line: <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">train.py</span></code>.</p></li>
<li><p>A directory structure of reusable Python scripts, such as:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>going_modular/
├── going_modular/
│   ├── data_setup.py
│   ├── engine.py
│   ├── model_builder.py
│   ├── train.py
│   └── utils.py
├── models/
│   ├── 05_going_modular_cell_mode_tinyvgg_model.pth
│   └── 05_going_modular_script_mode_tinyvgg_model.pth
└── data/
    └── pizza_steak_sushi/
        ├── train/
        │   ├── pizza/
        │   │   ├── image01.jpeg
        │   │   └── ...
        │   ├── steak/
        │   └── sushi/
        └── test/
            ├── pizza/
            ├── steak/
            └── sushi/
</pre></div>
</div>
</section>
<section id="things-to-note">
<h3>Things to note<a class="headerlink" href="#things-to-note" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Docstrings</strong> - Writing reproducible and understandable code is important. And with this in mind, each of the functions/classes we’ll be putting into scripts has been created with Google’s <a class="reference external" href="https://google.github.io/styleguide/pyguide.html#383-functions-and-methods">Python docstring style in mind</a>.</p></li>
<li><p><strong>Imports at the top of scripts</strong> - Since all of the Python scripts we’re going to create could be considered a small program on their own, all of the scripts require their input modules be imported at the start of the script for example:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import modules required for train.py</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">data_setup</span><span class="o">,</span> <span class="nn">engine</span><span class="o">,</span> <span class="nn">model_builder</span><span class="o">,</span> <span class="nn">utils</span>

<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
</pre></div>
</div>
</section>
</section>
<section id="where-can-you-get-help">
<h2>Where can you get help?<a class="headerlink" href="#where-can-you-get-help" title="Permalink to this heading">#</a></h2>
<p>All of the materials for this course <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning">are available on GitHub</a>.</p>
<p>If you run into trouble, you can ask a question on the course <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/discussions">GitHub Discussions page</a>.</p>
<p>And of course, there’s the <a class="reference external" href="https://pytorch.org/docs/stable/index.html">PyTorch documentation</a> and <a class="reference external" href="https://discuss.pytorch.org/">PyTorch developer forums</a>, a very helpful place for all things PyTorch.</p>
</section>
<section id="cell-mode-vs-script-mode">
<h2>0. Cell mode vs. script mode<a class="headerlink" href="#cell-mode-vs-script-mode" title="Permalink to this heading">#</a></h2>
<p>A cell mode notebook such as <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_cell_mode.ipynb">05. Going Modular Part 1 (cell mode)</a> is a notebook run normally, each cell in the notebook is either code or markdown.</p>
<p>A script mode notebook such as <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/going_modular/05_pytorch_going_modular_script_mode.ipynb">05. Going Modular Part 2 (script mode)</a> is very similar to a cell mode notebook, however, many of the code cells may be turned into Python scripts.</p>
<blockquote>
<div><p><strong>Note:</strong> You don’t <em>need</em> to create Python scripts via a notebook, you can create them directly through an IDE (integrated developer environment) such as <a class="reference external" href="https://code.visualstudio.com/">VS Code</a>. Having the script mode notebook as part of this section is just to demonstrate one way of going from notebooks to Python scripts.</p>
</div></blockquote>
</section>
<section id="get-data">
<h2>1. Get data<a class="headerlink" href="#get-data" title="Permalink to this heading">#</a></h2>
<p>Getting the data in each of the 05 notebooks happens the same as in <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#1-get-data">notebook 04</a>.</p>
<p>A call is made to GitHub via Python’s <code class="docutils literal notranslate"><span class="pre">requests</span></code> module to download a <code class="docutils literal notranslate"><span class="pre">.zip</span></code> file and unzip it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="c1"># Setup path to data folder</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span><span class="p">)</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="n">data_path</span> <span class="o">/</span> <span class="s2">&quot;pizza_steak_sushi&quot;</span>

<span class="c1"># If the image folder doesn&#39;t exist, download it and prepare it...</span>
<span class="k">if</span> <span class="n">image_path</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2"> directory exists.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Did not find </span><span class="si">{</span><span class="n">image_path</span><span class="si">}</span><span class="s2"> directory, creating one...&quot;</span><span class="p">)</span>
    <span class="n">image_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Download pizza, steak, sushi data</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data_path</span> <span class="o">/</span> <span class="s2">&quot;pizza_steak_sushi.zip&quot;</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">request</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading pizza, steak, sushi data...&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">request</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># Unzip pizza, steak, sushi data</span>
<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="n">data_path</span> <span class="o">/</span> <span class="s2">&quot;pizza_steak_sushi.zip&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Unzipping pizza, steak, sushi data...&quot;</span><span class="p">)</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>

<span class="c1"># Remove zip file</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">data_path</span> <span class="o">/</span> <span class="s2">&quot;pizza_steak_sushi.zip&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This results in having a file called <code class="docutils literal notranslate"><span class="pre">data</span></code> that contains another directory called <code class="docutils literal notranslate"><span class="pre">pizza_steak_sushi</span></code> with images of pizza, steak and sushi in standard image classification format.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>data/
└── pizza_steak_sushi/
    ├── train/
    │   ├── pizza/
    │   │   ├── train_image01.jpeg
    │   │   ├── test_image02.jpeg
    │   │   └── ...
    │   ├── steak/
    │   │   └── ...
    │   └── sushi/
    │       └── ...
    └── test/
        ├── pizza/
        │   ├── test_image01.jpeg
        │   └── test_image02.jpeg
        ├── steak/
        └── sushi/
</pre></div>
</div>
</section>
<section id="create-datasets-and-dataloaders-data-setup-py">
<h2>2. Create Datasets and DataLoaders (<code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code>)<a class="headerlink" href="#create-datasets-and-dataloaders-data-setup-py" title="Permalink to this heading">#</a></h2>
<p>Once we’ve got data, we can then turn it into PyTorch <code class="docutils literal notranslate"><span class="pre">Dataset</span></code>’s and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>’s (one for training data and one for testing data).</p>
<p>We convert the useful <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> creation code into a function called <code class="docutils literal notranslate"><span class="pre">create_dataloaders()</span></code>.</p>
<p>And we write it to file using the line <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">going_modular/data_setup.py</span></code>.</p>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">going_modular</span><span class="o">/</span><span class="n">data_setup</span><span class="o">.</span><span class="n">py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Contains functionality for creating PyTorch DataLoaders for</span>
<span class="sd">image classification data.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">create_dataloaders</span><span class="p">(</span>
    <span class="n">train_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">test_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">transform</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="n">NUM_WORKERS</span>
<span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Creates training and testing DataLoaders.</span>

<span class="sd">  Takes in a training directory and testing directory path and turns</span>
<span class="sd">  them into PyTorch Datasets and then into PyTorch DataLoaders.</span>

<span class="sd">  Args:</span>
<span class="sd">    train_dir: Path to training directory.</span>
<span class="sd">    test_dir: Path to testing directory.</span>
<span class="sd">    transform: torchvision transforms to perform on training and testing data.</span>
<span class="sd">    batch_size: Number of samples per batch in each of the DataLoaders.</span>
<span class="sd">    num_workers: An integer for number of workers per DataLoader.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of (train_dataloader, test_dataloader, class_names).</span>
<span class="sd">    Where class_names is a list of the target classes.</span>
<span class="sd">    Example usage:</span>
<span class="sd">      train_dataloader, test_dataloader, class_names = \</span>
<span class="sd">        = create_dataloaders(train_dir=path/to/train_dir,</span>
<span class="sd">                             test_dir=path/to/test_dir,</span>
<span class="sd">                             transform=some_transform,</span>
<span class="sd">                             batch_size=32,</span>
<span class="sd">                             num_workers=4)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Use ImageFolder to create dataset(s)</span>
  <span class="n">train_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">train_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
  <span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">test_dir</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

  <span class="c1"># Get class names</span>
  <span class="n">class_names</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">classes</span>

  <span class="c1"># Turn images into data loaders</span>
  <span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
      <span class="n">train_data</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
      <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
      <span class="n">test_data</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
      <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
      <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="p">)</span>

  <span class="k">return</span> <span class="n">train_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">class_names</span>
</pre></div>
</div>
<p>If we’d like to make <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>’s we can now use the function within <code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code> like so:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import data_setup.py</span>
<span class="kn">from</span> <span class="nn">going_modular</span> <span class="kn">import</span> <span class="n">data_setup</span>

<span class="c1"># Create train/test dataloader and get class names as a list</span>
<span class="n">train_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="making-a-model-model-builder-py">
<h2>3. Making a model (<code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code>)<a class="headerlink" href="#making-a-model-model-builder-py" title="Permalink to this heading">#</a></h2>
<p>Over the past few notebooks (notebook 03 and notebook 04), we’ve built the TinyVGG model a few times.</p>
<p>So it makes sense to put the model into its file so we can reuse it again and again.</p>
<p>Let’s put our <code class="docutils literal notranslate"><span class="pre">TinyVGG()</span></code> model class into a script with the line <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">going_modular/model_builder.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">going_modular</span><span class="o">/</span><span class="n">model_builder</span><span class="o">.</span><span class="n">py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Contains PyTorch model code to instantiate a TinyVGG model.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>

<span class="k">class</span> <span class="nc">TinyVGG</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Creates the TinyVGG architecture.</span>

<span class="sd">  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.</span>
<span class="sd">  See the original architecture here: https://poloclub.github.io/cnn-explainer/</span>

<span class="sd">  Args:</span>
<span class="sd">    input_shape: An integer indicating number of input channels.</span>
<span class="sd">    hidden_units: An integer indicating number of hidden units between layers.</span>
<span class="sd">    output_shape: An integer indicating number of output units.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">conv_block_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
                    <span class="n">out_channels</span><span class="o">=</span><span class="n">hidden_units</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">conv_block_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">,</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
      <span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
          <span class="c1"># Where did this in_features shape come from?</span>
          <span class="c1"># It&#39;s because each layer of our network compresses and changes the shape of our inputs data.</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="n">hidden_units</span><span class="o">*</span><span class="mi">13</span><span class="o">*</span><span class="mi">13</span><span class="p">,</span>
                    <span class="n">out_features</span><span class="o">=</span><span class="n">output_shape</span><span class="p">)</span>
      <span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block_1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block_2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">x</span>
      <span class="c1"># return self.classifier(self.conv_block_2(self.conv_block_1(x))) # &lt;- leverage the benefits of operator fusion</span>
</pre></div>
</div>
<p>Now instead of coding the TinyVGG model from scratch every time, we can import it using:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># Import model_builder.py</span>
<span class="kn">from</span> <span class="nn">going_modular</span> <span class="kn">import</span> <span class="n">model_builder</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Instantiate an instance of the model from the &quot;model_builder.py&quot; script</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_builder</span><span class="o">.</span><span class="n">TinyVGG</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                              <span class="n">hidden_units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                              <span class="n">output_shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="creating-train-step-and-test-step-functions-and-train-to-combine-them">
<h2>4. Creating <code class="docutils literal notranslate"><span class="pre">train_step()</span></code> and <code class="docutils literal notranslate"><span class="pre">test_step()</span></code> functions and <code class="docutils literal notranslate"><span class="pre">train()</span></code> to combine them<a class="headerlink" href="#creating-train-step-and-test-step-functions-and-train-to-combine-them" title="Permalink to this heading">#</a></h2>
<p>We wrote several training functions in <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#75-create-train-test-loop-functions">notebook 04</a>:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">train_step()</span></code> - takes in a model, a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>, a loss function and an optimizer and trains the model on the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_step()</span></code> - takes in a model, a <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code> and a loss function and evaluates the model on the <code class="docutils literal notranslate"><span class="pre">DataLoader</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">train()</span></code> - performs 1. and 2. together for a given number of epochs and returns a results dictionary.</p></li>
</ol>
<p>Since these will be the <em>engine</em> of our model training, we can put them all into a Python script called <code class="docutils literal notranslate"><span class="pre">engine.py</span></code> with the line <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">going_modular/engine.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">going_modular</span><span class="o">/</span><span class="n">engine</span><span class="o">.</span><span class="n">py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Contains functions for training and testing a PyTorch model.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
               <span class="n">dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
               <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
               <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
               <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Trains a PyTorch model for a single epoch.</span>

<span class="sd">  Turns a target PyTorch model to training mode and then</span>
<span class="sd">  runs through all of the required training steps (forward</span>
<span class="sd">  pass, loss calculation, optimizer step).</span>

<span class="sd">  Args:</span>
<span class="sd">    model: A PyTorch model to be trained.</span>
<span class="sd">    dataloader: A DataLoader instance for the model to be trained on.</span>
<span class="sd">    loss_fn: A PyTorch loss function to minimize.</span>
<span class="sd">    optimizer: A PyTorch optimizer to help minimize the loss function.</span>
<span class="sd">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of training loss and training accuracy metrics.</span>
<span class="sd">    In the form (train_loss, train_accuracy). For example:</span>

<span class="sd">    (0.1112, 0.8743)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Put model in train mode</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="c1"># Setup train loss and train accuracy values</span>
  <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

  <span class="c1"># Loop through data loader data batches</span>
  <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
      <span class="c1"># Send data to target device</span>
      <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

      <span class="c1"># 1. Forward pass</span>
      <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

      <span class="c1"># 2. Calculate  and accumulate loss</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
      <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

      <span class="c1"># 3. Optimizer zero grad</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

      <span class="c1"># 4. Loss backward</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

      <span class="c1"># 5. Optimizer step</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># Calculate and accumulate accuracy metric across all batches</span>
      <span class="n">y_pred_class</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
      <span class="n">train_acc</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y_pred_class</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

  <span class="c1"># Adjust metrics to get average loss and accuracy per batch</span>
  <span class="n">train_loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
  <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span>

<span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
              <span class="n">dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
              <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
              <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Tests a PyTorch model for a single epoch.</span>

<span class="sd">  Turns a target PyTorch model to &quot;eval&quot; mode and then performs</span>
<span class="sd">  a forward pass on a testing dataset.</span>

<span class="sd">  Args:</span>
<span class="sd">    model: A PyTorch model to be tested.</span>
<span class="sd">    dataloader: A DataLoader instance for the model to be tested on.</span>
<span class="sd">    loss_fn: A PyTorch loss function to calculate loss on the test data.</span>
<span class="sd">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A tuple of testing loss and testing accuracy metrics.</span>
<span class="sd">    In the form (test_loss, test_accuracy). For example:</span>

<span class="sd">    (0.0223, 0.8985)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Put model in eval mode</span>
  <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

  <span class="c1"># Setup test loss and test accuracy values</span>
  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>

  <span class="c1"># Turn on inference context manager</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
      <span class="c1"># Loop through DataLoader batches</span>
      <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
          <span class="c1"># Send data to target device</span>
          <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

          <span class="c1"># 1. Forward pass</span>
          <span class="n">test_pred_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

          <span class="c1"># 2. Calculate and accumulate loss</span>
          <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">test_pred_logits</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
          <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

          <span class="c1"># Calculate and accumulate accuracy</span>
          <span class="n">test_pred_labels</span> <span class="o">=</span> <span class="n">test_pred_logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
          <span class="n">test_acc</span> <span class="o">+=</span> <span class="p">((</span><span class="n">test_pred_labels</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_pred_labels</span><span class="p">))</span>

  <span class="c1"># Adjust metrics to get average loss and accuracy per batch</span>
  <span class="n">test_loss</span> <span class="o">=</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
  <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
          <span class="n">train_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
          <span class="n">test_dataloader</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">,</span>
          <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span>
          <span class="n">loss_fn</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
          <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
          <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Trains and tests a PyTorch model.</span>

<span class="sd">  Passes a target PyTorch models through train_step() and test_step()</span>
<span class="sd">  functions for a number of epochs, training and testing the model</span>
<span class="sd">  in the same epoch loop.</span>

<span class="sd">  Calculates, prints and stores evaluation metrics throughout.</span>

<span class="sd">  Args:</span>
<span class="sd">    model: A PyTorch model to be trained and tested.</span>
<span class="sd">    train_dataloader: A DataLoader instance for the model to be trained on.</span>
<span class="sd">    test_dataloader: A DataLoader instance for the model to be tested on.</span>
<span class="sd">    optimizer: A PyTorch optimizer to help minimize the loss function.</span>
<span class="sd">    loss_fn: A PyTorch loss function to calculate loss on both datasets.</span>
<span class="sd">    epochs: An integer indicating how many epochs to train for.</span>
<span class="sd">    device: A target device to compute on (e.g. &quot;cuda&quot; or &quot;cpu&quot;).</span>

<span class="sd">  Returns:</span>
<span class="sd">    A dictionary of training and testing loss as well as training and</span>
<span class="sd">    testing accuracy metrics. Each metric has a value in a list for</span>
<span class="sd">    each epoch.</span>
<span class="sd">    In the form: {train_loss: [...],</span>
<span class="sd">                  train_acc: [...],</span>
<span class="sd">                  test_loss: [...],</span>
<span class="sd">                  test_acc: [...]}</span>
<span class="sd">    For example if training for epochs=2:</span>
<span class="sd">                 {train_loss: [2.0616, 1.0537],</span>
<span class="sd">                  train_acc: [0.3945, 0.3945],</span>
<span class="sd">                  test_loss: [1.2641, 1.5706],</span>
<span class="sd">                  test_acc: [0.3400, 0.2973]}</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Create empty results dictionary</span>
  <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;train_loss&quot;</span><span class="p">:</span> <span class="p">[],</span>
      <span class="s2">&quot;train_acc&quot;</span><span class="p">:</span> <span class="p">[],</span>
      <span class="s2">&quot;test_loss&quot;</span><span class="p">:</span> <span class="p">[],</span>
      <span class="s2">&quot;test_acc&quot;</span><span class="p">:</span> <span class="p">[]</span>
  <span class="p">}</span>

  <span class="c1"># Loop through training and testing steps for a number of epochs</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
      <span class="n">train_loss</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                                          <span class="n">dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span>
                                          <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
                                          <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                                          <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
      <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test_step</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
          <span class="n">dataloader</span><span class="o">=</span><span class="n">test_dataloader</span><span class="p">,</span>
          <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
          <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

      <span class="c1"># Print out what&#39;s happening</span>
      <span class="nb">print</span><span class="p">(</span>
          <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> | &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;train_loss: </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;train_acc: </span><span class="si">{</span><span class="n">train_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;test_loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | &quot;</span>
          <span class="sa">f</span><span class="s2">&quot;test_acc: </span><span class="si">{</span><span class="n">test_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span>
      <span class="p">)</span>

      <span class="c1"># Update results dictionary</span>
      <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="p">)</span>
      <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_acc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_acc</span><span class="p">)</span>
      <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
      <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_acc&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>

  <span class="c1"># Return the filled results at the end of the epochs</span>
  <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
<p>Now we’ve got the <code class="docutils literal notranslate"><span class="pre">engine.py</span></code> script, we can import functions from it via:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import engine.py</span>
<span class="kn">from</span> <span class="nn">going_modular</span> <span class="kn">import</span> <span class="n">engine</span>

<span class="c1"># Use train() by calling it from engine.py</span>
<span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="creating-a-function-to-save-the-model-utils-py">
<h2>5. Creating a function to save the model (<code class="docutils literal notranslate"><span class="pre">utils.py</span></code>)<a class="headerlink" href="#creating-a-function-to-save-the-model-utils-py" title="Permalink to this heading">#</a></h2>
<p>Often you’ll want to save a model whilst it’s training or after training.</p>
<p>Since we’ve written the code to save a model a few times now in previous notebooks, it makes sense to turn it into a function and save it to file.</p>
<p>It’s common practice to store helper functions in a file called <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> (short for utilities).</p>
<p>Let’s save our <code class="docutils literal notranslate"><span class="pre">save_model()</span></code> function to a file called <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> with the line <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">going_modular/utils.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">going_modular</span><span class="o">/</span><span class="n">utils</span><span class="o">.</span><span class="n">py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Contains various utility functions for PyTorch model training and saving.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
               <span class="n">target_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
               <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Saves a PyTorch model to a target directory.</span>

<span class="sd">  Args:</span>
<span class="sd">    model: A target PyTorch model to save.</span>
<span class="sd">    target_dir: A directory for saving the model to.</span>
<span class="sd">    model_name: A filename for the saved model. Should include</span>
<span class="sd">      either &quot;.pth&quot; or &quot;.pt&quot; as the file extension.</span>

<span class="sd">  Example usage:</span>
<span class="sd">    save_model(model=model_0,</span>
<span class="sd">               target_dir=&quot;models&quot;,</span>
<span class="sd">               model_name=&quot;05_going_modular_tingvgg_model.pth&quot;)</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Create target directory</span>
  <span class="n">target_dir_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">target_dir</span><span class="p">)</span>
  <span class="n">target_dir_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="c1"># Create model save path</span>
  <span class="k">assert</span> <span class="n">model_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.pth&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">model_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.pt&quot;</span><span class="p">),</span> <span class="s2">&quot;model_name should end with &#39;.pt&#39; or &#39;.pth&#39;&quot;</span>
  <span class="n">model_save_path</span> <span class="o">=</span> <span class="n">target_dir_path</span> <span class="o">/</span> <span class="n">model_name</span>

  <span class="c1"># Save the model state_dict()</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[INFO] Saving model to: </span><span class="si">{</span><span class="n">model_save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">obj</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
             <span class="n">f</span><span class="o">=</span><span class="n">model_save_path</span><span class="p">)</span>
</pre></div>
</div>
<p>Now if we wanted to use our <code class="docutils literal notranslate"><span class="pre">save_model()</span></code> function, instead of writing it all over again, we can import it and use it via:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import utils.py</span>
<span class="kn">from</span> <span class="nn">going_modular</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="c1"># Save a model to file</span>
<span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=...</span>
           <span class="n">target_dir</span><span class="o">=...</span><span class="p">,</span>
           <span class="n">model_name</span><span class="o">=...</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="train-evaluate-and-save-the-model-train-py">
<h2>6. Train, evaluate and save the model (<code class="docutils literal notranslate"><span class="pre">train.py</span></code>)<a class="headerlink" href="#train-evaluate-and-save-the-model-train-py" title="Permalink to this heading">#</a></h2>
<p>As previously discussed, you’ll often come across PyTorch repositories that combine all of their functionality together in a <code class="docutils literal notranslate"><span class="pre">train.py</span></code> file.</p>
<p>This file is essentially saying “train the model using whatever data is available”.</p>
<p>In our <code class="docutils literal notranslate"><span class="pre">train.py</span></code> file, we’ll combine all of the functionality of the other Python scripts we’ve created and use it to train a model.</p>
<p>This way we can train a PyTorch model using a single line of code on the command line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>To create <code class="docutils literal notranslate"><span class="pre">train.py</span></code> we’ll go through the following steps:</p>
<ol class="arabic simple">
<li><p>Import the various dependencies, namely <code class="docutils literal notranslate"><span class="pre">torch</span></code>, <code class="docutils literal notranslate"><span class="pre">os</span></code>, <code class="docutils literal notranslate"><span class="pre">torchvision.transforms</span></code> and all of the scripts from the <code class="docutils literal notranslate"><span class="pre">going_modular</span></code> directory, <code class="docutils literal notranslate"><span class="pre">data_setup</span></code>, <code class="docutils literal notranslate"><span class="pre">engine</span></code>, <code class="docutils literal notranslate"><span class="pre">model_builder</span></code>, <code class="docutils literal notranslate"><span class="pre">utils</span></code>.</p></li>
</ol>
<ul class="simple">
<li><p><strong>Note:</strong> Since <code class="docutils literal notranslate"><span class="pre">train.py</span></code> will be <em>inside</em> the <code class="docutils literal notranslate"><span class="pre">going_modular</span></code> directory, we can import the other modules via <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">...</span></code> rather than <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">going_modular</span> <span class="pre">import</span> <span class="pre">...</span></code>.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Setup various hyperparameters such as batch size, number of epochs, learning rate and number of hidden units (these could be set in the future via <a class="reference external" href="https://docs.python.org/3/library/argparse.html">Python’s <code class="docutils literal notranslate"><span class="pre">argparse</span></code></a>).</p></li>
<li><p>Setup the training and test directories.</p></li>
<li><p>Setup device-agnostic code.</p></li>
<li><p>Create the necessary data transforms.</p></li>
<li><p>Create the DataLoaders using <code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code>.</p></li>
<li><p>Create the model using <code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code>.</p></li>
<li><p>Setup the loss function and optimizer.</p></li>
<li><p>Train the model using <code class="docutils literal notranslate"><span class="pre">engine.py</span></code>.</p></li>
<li><p>Save the model using <code class="docutils literal notranslate"><span class="pre">utils.py</span></code>.</p></li>
</ol>
<p>And we can create the file from a notebook cell using the line <code class="docutils literal notranslate"><span class="pre">%%writefile</span> <span class="pre">going_modular/train.py</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">%%</span><span class="n">writefile</span> <span class="n">going_modular</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">py</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Trains a PyTorch image classification model using device-agnostic code.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">data_setup</span><span class="o">,</span> <span class="nn">engine</span><span class="o">,</span> <span class="nn">model_builder</span><span class="o">,</span> <span class="nn">utils</span>

<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="c1"># Setup hyperparameters</span>
<span class="n">NUM_EPOCHS</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">HIDDEN_UNITS</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.001</span>

<span class="c1"># Setup directories</span>
<span class="n">train_dir</span> <span class="o">=</span> <span class="s2">&quot;data/pizza_steak_sushi/train&quot;</span>
<span class="n">test_dir</span> <span class="o">=</span> <span class="s2">&quot;data/pizza_steak_sushi/test&quot;</span>

<span class="c1"># Setup target device</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Create transforms</span>
<span class="n">data_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
  <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)),</span>
  <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">])</span>

<span class="c1"># Create DataLoaders with help from data_setup.py</span>
<span class="n">train_dataloader</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">class_names</span> <span class="o">=</span> <span class="n">data_setup</span><span class="o">.</span><span class="n">create_dataloaders</span><span class="p">(</span>
    <span class="n">train_dir</span><span class="o">=</span><span class="n">train_dir</span><span class="p">,</span>
    <span class="n">test_dir</span><span class="o">=</span><span class="n">test_dir</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">data_transform</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span>
<span class="p">)</span>

<span class="c1"># Create model with help from model_builder.py</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model_builder</span><span class="o">.</span><span class="n">TinyVGG</span><span class="p">(</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">hidden_units</span><span class="o">=</span><span class="n">HIDDEN_UNITS</span><span class="p">,</span>
    <span class="n">output_shape</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_names</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Set loss and optimizer</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                             <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>

<span class="c1"># Start training with help from engine.py</span>
<span class="n">engine</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
             <span class="n">train_dataloader</span><span class="o">=</span><span class="n">train_dataloader</span><span class="p">,</span>
             <span class="n">test_dataloader</span><span class="o">=</span><span class="n">test_dataloader</span><span class="p">,</span>
             <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
             <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
             <span class="n">epochs</span><span class="o">=</span><span class="n">NUM_EPOCHS</span><span class="p">,</span>
             <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># Save the model with help from utils.py</span>
<span class="n">utils</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                 <span class="n">target_dir</span><span class="o">=</span><span class="s2">&quot;models&quot;</span><span class="p">,</span>
                 <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;05_going_modular_script_mode_tinyvgg_model.pth&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Woohoo!</p>
<p>Now we can train a PyTorch model by running the following line on the command line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Doing this will leverage all of the other code scripts we’ve created.</p>
<p>And if we wanted to, we could adjust our <code class="docutils literal notranslate"><span class="pre">train.py</span></code> file to use argument flag inputs with Python’s <code class="docutils literal notranslate"><span class="pre">argparse</span></code> module, this would allow us to provide different hyperparameter settings like previously discussed:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">model</span> <span class="n">MODEL_NAME</span> <span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span> <span class="o">--</span><span class="n">lr</span> <span class="n">LEARNING_RATE</span> <span class="o">--</span><span class="n">num_epochs</span> <span class="n">NUM_EPOCHS</span>
</pre></div>
</div>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<p><strong>Resources:</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/05_pytorch_going_modular_exercise_template.ipynb">Exercise template notebook for 05</a></p></li>
<li><p><a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/05_pytorch_going_modular_exercise_solutions.ipynb">Example solutions notebook for 05</a></p>
<ul>
<li><p>Live coding run through of <a class="reference external" href="https://youtu.be/ijgFhMK3pp4">solutions notebook for 05 on YouTube</a></p></li>
</ul>
</li>
</ul>
<p><strong>Exercises:</strong></p>
<ol class="arabic simple">
<li><p>Turn the code to get the data (from section 1. Get Data above) into a Python script, such as <code class="docutils literal notranslate"><span class="pre">get_data.py</span></code>.</p>
<ul class="simple">
<li><p>When you run the script using <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">get_data.py</span></code> it should check if the data already exists and skip downloading if it does.</p></li>
<li><p>If the data download is successful, you should be able to access the <code class="docutils literal notranslate"><span class="pre">pizza_steak_sushi</span></code> images from the <code class="docutils literal notranslate"><span class="pre">data</span></code> directory.</p></li>
</ul>
</li>
<li><p>Use <a class="reference external" href="https://docs.python.org/3/library/argparse.html">Python’s <code class="docutils literal notranslate"><span class="pre">argparse</span></code> module</a> to be able to send the <code class="docutils literal notranslate"><span class="pre">train.py</span></code> custom hyperparameter values for training procedures.</p>
<ul class="simple">
<li><p>Add an argument for using a different:</p>
<ul>
<li><p>Training/testing directory</p></li>
<li><p>Learning rate</p></li>
<li><p>Batch size</p></li>
<li><p>Number of epochs to train for</p></li>
<li><p>Number of hidden units in the TinyVGG model</p></li>
</ul>
</li>
<li><p>Keep the default values for each of the above arguments as what they already are (as in notebook 05).</p></li>
<li><p>For example, you should be able to run something similar to the following line to train a TinyVGG model with a learning rate of 0.003 and a batch size of 64 for 20 epochs: <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">train.py</span> <span class="pre">--learning_rate</span> <span class="pre">0.003</span> <span class="pre">--batch_size</span> <span class="pre">64</span> <span class="pre">--num_epochs</span> <span class="pre">20</span></code>.</p></li>
<li><p><strong>Note:</strong> Since <code class="docutils literal notranslate"><span class="pre">train.py</span></code> leverages the other scripts we created in section 05, such as, <code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code>, <code class="docutils literal notranslate"><span class="pre">utils.py</span></code> and <code class="docutils literal notranslate"><span class="pre">engine.py</span></code>, you’ll have to make sure they’re available to use too. You can find these in the <a class="reference external" href="https://github.com/mrdbourke/pytorch-deep-learning/tree/main/going_modular/going_modular"><code class="docutils literal notranslate"><span class="pre">going_modular</span></code> folder on the course GitHub</a>.</p></li>
</ul>
</li>
<li><p>Create a script to predict (such as <code class="docutils literal notranslate"><span class="pre">predict.py</span></code>) on a target image given a file path with a saved model.</p>
<ul class="simple">
<li><p>For example, you should be able to run the command <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">predict.py</span> <span class="pre">some_image.jpeg</span></code> and have a trained PyTorch model predict on the image and return its prediction.</p></li>
<li><p>To see example prediction code, check out the <a class="reference external" href="https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function">predicting on a custom image section in notebook 04</a>.</p></li>
<li><p>You may also have to write code to load in a trained model.</p></li>
</ul>
</li>
</ol>
</section>
<section id="extra-curriculum">
<h2>Extra-curriculum<a class="headerlink" href="#extra-curriculum" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>To learn more about structuring a Python project, check out Real Python’s guide on <a class="reference external" href="https://realpython.com/python-application-layouts/">Python Application Layouts</a>.</p></li>
<li><p>For ideas on styling your PyTorch code, check out the <a class="reference external" href="https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model">PyTorch style guide by Igor Susmelj</a> (much of styling in this chapter is based off this guide + various similar PyTorch repositories).</p></li>
<li><p>For an example <code class="docutils literal notranslate"><span class="pre">train.py</span></code> script and various other PyTorch scripts written by the PyTorch team to train state-of-the-art image classification models, check out their <a class="reference external" href="https://github.com/pytorch/vision/tree/main/references/classification"><code class="docutils literal notranslate"><span class="pre">classification</span></code> repository on GitHub</a>.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebook/pytorch_deep_learning"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="04_pytorch_custom_datasets.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">04. PyTorch Custom Datasets</p>
      </div>
    </a>
    <a class="right-next"
       href="06_pytorch_transfer_learning.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">06. PyTorch Transfer Learning</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-going-modular">What is going modular?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-would-you-want-to-go-modular">Why would you want to go modular?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pros-and-cons-of-notebooks-vs-python-scripts">Pros and cons of notebooks vs Python scripts</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#my-workflow">My workflow</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pytorch-in-the-wild">PyTorch in the wild</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-were-going-to-cover">What we’re going to cover</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-two-parts">Why two parts?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-were-working-towards">What we’re working towards</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#things-to-note">Things to note</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#where-can-you-get-help">Where can you get help?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cell-mode-vs-script-mode">0. Cell mode vs. script mode</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-data">1. Get data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#create-datasets-and-dataloaders-data-setup-py">2. Create Datasets and DataLoaders (<code class="docutils literal notranslate"><span class="pre">data_setup.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#making-a-model-model-builder-py">3. Making a model (<code class="docutils literal notranslate"><span class="pre">model_builder.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-train-step-and-test-step-functions-and-train-to-combine-them">4. Creating <code class="docutils literal notranslate"><span class="pre">train_step()</span></code> and <code class="docutils literal notranslate"><span class="pre">test_step()</span></code> functions and <code class="docutils literal notranslate"><span class="pre">train()</span></code> to combine them</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-function-to-save-the-model-utils-py">5. Creating a function to save the model (<code class="docutils literal notranslate"><span class="pre">utils.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#train-evaluate-and-save-the-model-train-py">6. Train, evaluate and save the model (<code class="docutils literal notranslate"><span class="pre">train.py</span></code>)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extra-curriculum">Extra-curriculum</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By thangckt
</p>

  </div>
  
  <div class="footer-item">
    

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>